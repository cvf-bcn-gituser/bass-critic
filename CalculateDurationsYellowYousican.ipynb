{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "CalculateDurationsYellowYousican.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRkoU7vdT6o6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46a56b28-0808-4a42-a649-b568a7323c29"
      },
      "source": [
        "!pip3 install essentia\n",
        "!pip3 install madmom\n",
        "!pip3 install mir_eval"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting essentia\n",
            "  Downloading essentia-2.1b6.dev778-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 13.6 MB 24.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.7/dist-packages (from essentia) (1.21.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from essentia) (3.13)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from essentia) (1.15.0)\n",
            "Installing collected packages: essentia\n",
            "Successfully installed essentia-2.1b6.dev778\n",
            "Collecting madmom\n",
            "  Downloading madmom-0.16.1.tar.gz (20.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 20.0 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13.4 in /usr/local/lib/python3.7/dist-packages (from madmom) (1.21.5)\n",
            "Requirement already satisfied: scipy>=0.16 in /usr/local/lib/python3.7/dist-packages (from madmom) (1.4.1)\n",
            "Requirement already satisfied: cython>=0.25 in /usr/local/lib/python3.7/dist-packages (from madmom) (0.29.28)\n",
            "Collecting mido>=1.2.8\n",
            "  Downloading mido-1.2.10-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 6.7 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: madmom\n",
            "  Building wheel for madmom (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for madmom: filename=madmom-0.16.1-cp37-cp37m-linux_x86_64.whl size=20935881 sha256=f489408ff4ee8ff50d2528ef40d5a7a9a0ca78be1f3bb599eca8e66bfb6a19b5\n",
            "  Stored in directory: /root/.cache/pip/wheels/af/90/61/393ceef814b55b12d1b59b5ed3a2b2a3457a55d39b7363b975\n",
            "Successfully built madmom\n",
            "Installing collected packages: mido, madmom\n",
            "Successfully installed madmom-0.16.1 mido-1.2.10\n",
            "Collecting mir_eval\n",
            "  Downloading mir_eval-0.7.tar.gz (90 kB)\n",
            "\u001b[K     |████████████████████████████████| 90 kB 6.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from mir_eval) (1.21.5)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from mir_eval) (1.4.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from mir_eval) (0.16.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from mir_eval) (1.15.0)\n",
            "Building wheels for collected packages: mir-eval\n",
            "  Building wheel for mir-eval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mir-eval: filename=mir_eval-0.7-py3-none-any.whl size=100721 sha256=9ee6fe654eea7d994f686ed9416eec44b2d1d7a54fb343000dc16a69449b4bff\n",
            "  Stored in directory: /root/.cache/pip/wheels/18/5a/46/d2527ff1fd975e1a793375e6ed763bfe4d3ea396b7cdc470eb\n",
            "Successfully built mir-eval\n",
            "Installing collected packages: mir-eval\n",
            "Successfully installed mir-eval-0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNDZIqXIT-8C"
      },
      "source": [
        "# first, we need to import our essentia module. It is aptly named 'essentia'!\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "import pandas as pd\n",
        "import sys\n",
        "import os\n",
        "from essentia.standard import *\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import IPython.display as ipd\n",
        "import madmom\n",
        "import scipy\n",
        "from scipy.signal import find_peaks\n",
        "from mir_eval import *\n",
        "from statistics import mean\n",
        "import math\n",
        "from math import sqrt\n",
        "import csv  \n",
        "import pickle\n",
        "from pickle import load\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.io.wavfile import write, read\n",
        "INT16_FAC = (2**15)-1\n",
        "INT32_FAC = (2**31)-1\n",
        "INT64_FAC = (2**63)-1\n",
        "norm_fact = {'int16':INT16_FAC, 'int32':INT32_FAC, 'int64':INT64_FAC,'float32':1.0,'float64':1.0}\n",
        "import math, copy, sys, os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount(\"/content/drive\", force_remount=True)\n",
        "root = '/content/drive/Thesis'\n",
        "query_music_path = '/content/drive/Thesis'\n",
        "sys.path.append('/content/drive/Thesis')"
      ],
      "metadata": {
        "id": "nk3v1xR4VxjV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c49ce81f-c74c-4ede-eda1-37e3c425cf90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "AUDIO_PATH = 'drive/MyDrive/Thesis/Experiments/audio'\n",
        "DATA_PATH = 'drive/MyDrive/Thesis/Experiments/data'\n",
        "dash= '/'\n",
        "yellowTag = 'yellow'\n",
        "yellowStem =  'Yellow88mono'\n",
        "fileSuffix = '.wav'\n",
        "yellowStemPrefix =  AUDIO_PATH + dash + yellowStem\n"
      ],
      "metadata": {
        "id": "20w0gl8tlX-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yellowStudentAudio1  = AUDIO_PATH + dash + yellowTag + dash + '1'+ dash + 'y1'\n",
        "yellowStudentAudio2  = AUDIO_PATH + dash + yellowTag + dash + '2'+ dash +'y2'\n",
        "yellowStudentAudio3  = AUDIO_PATH + dash + yellowTag + dash + '3'+ dash +'y3'\n",
        "yellowStudentAudio4  = AUDIO_PATH + dash + yellowTag + dash + '4'+ dash +'y4'\n",
        "yellowStudentAudio5  = AUDIO_PATH + dash + yellowTag + dash + '5'+ dash +'y5'\n",
        "yellowStudentAudio6  = AUDIO_PATH + dash + yellowTag + dash + '6'+ dash +'y6'\n",
        "yellowStudentAudio7  = AUDIO_PATH + dash + yellowTag + dash + '7'+ dash +'y7'\n",
        "yellowStudentAudio8  = AUDIO_PATH + dash + yellowTag + dash + '8'+ dash +'y8'\n",
        "yellowStudentAudio9  = AUDIO_PATH + dash + yellowTag + dash + '9'+ dash +'y9'\n",
        "yellowStudentAudio10  = AUDIO_PATH + dash + yellowTag + dash + '10'+ dash +'y10'\n",
        "yellowStudentAudio11  = AUDIO_PATH + dash + yellowTag + dash + '11'+ dash +'y11'\n",
        "yellowStudentAudio12  = AUDIO_PATH + dash + yellowTag + dash + '12'+ dash +'y12'\n",
        "yellowStudentAudio13  = AUDIO_PATH + dash + yellowTag + dash + '13'+ dash +'y13'\n",
        "yellowStudentAudio14  = AUDIO_PATH + dash + yellowTag + dash + '14'+ dash +'y14'\n",
        "yellowStudentAudio15  = AUDIO_PATH + dash + yellowTag + dash + '15'+ dash +'y15'\n",
        "yellowStudentAudio16  = AUDIO_PATH + dash + yellowTag + dash + '16'+ dash +'y16'\n",
        "yellowStudentAudio20  = AUDIO_PATH + dash + yellowTag + dash + '20'+ dash + 'y20'\n",
        "yellowStudentAudio21  = AUDIO_PATH + dash + yellowTag + dash + '21'+ dash + 'y21'\n",
        "yellowStudentAudio22  = AUDIO_PATH + dash + yellowTag + dash + '22'+ dash + 'y22'\n",
        "yellowStudentAudio23  = AUDIO_PATH + dash + yellowTag + dash + '23'+ dash + 'y23'\n",
        "yellowStudentAudio24  = AUDIO_PATH + dash + yellowTag + dash + '24'+ dash + 'y24'\n",
        "yellowStudentAudio25  = AUDIO_PATH + dash + yellowTag + dash + '25'+ dash + 'y25'\n",
        "yellowStudentAudio26  = AUDIO_PATH + dash + yellowTag + dash + '26'+ dash + 'y26'\n",
        "yellowStudentAudio27  = AUDIO_PATH + dash + yellowTag + dash + '27'+ dash + 'y27'\n",
        "yellowStudentAudio28  = AUDIO_PATH + dash + yellowTag + dash + '28'+ dash + 'y28'\n",
        "yellowStudentAudio29  = AUDIO_PATH + dash + yellowTag + dash + '29'+ dash + 'y29'\n",
        "yellowStudentAudio30  = AUDIO_PATH + dash + yellowTag + dash + '30'+ dash + 'y30'\n",
        "yellowStudentAudio31  = AUDIO_PATH + dash + yellowTag + dash + '31'+ dash + 'y31'\n",
        "yellowStudentAudio32  = AUDIO_PATH + dash + yellowTag + dash + '32'+ dash + 'y32'\n",
        "yellowStudentAudio33  = AUDIO_PATH + dash + yellowTag + dash + '33'+ dash + 'y33'\n",
        "studentFilenames = [yellowStudentAudio1,yellowStudentAudio2,yellowStudentAudio3,\n",
        "                    yellowStudentAudio4,yellowStudentAudio5,yellowStudentAudio6,\n",
        "                    yellowStudentAudio7,yellowStudentAudio8,yellowStudentAudio9,yellowStudentAudio10,\n",
        "                    yellowStudentAudio11,yellowStudentAudio12,yellowStudentAudio13,\n",
        "                    yellowStudentAudio14,yellowStudentAudio15,yellowStudentAudio16,\n",
        "                    yellowStudentAudio20,yellowStudentAudio21,yellowStudentAudio22,\n",
        "                    yellowStudentAudio23,\n",
        "                    yellowStudentAudio24,yellowStudentAudio25,yellowStudentAudio26,\n",
        "                    yellowStudentAudio27,yellowStudentAudio28,yellowStudentAudio29,\n",
        "                    yellowStudentAudio30,yellowStudentAudio31,yellowStudentAudio32,\n",
        "                    yellowStudentAudio33]\n"
      ],
      "metadata": {
        "id": "KCpdZXTcNN_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "SxBLUGRBFhUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "HfAo_cSGCH8O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Lets open the ground truths from teh files (rhythm files)\n",
        "\n",
        "df0 = pd.read_csv(DATA_PATH + dash + yellowTag + dash + 'yellow0_rhythm0.csv', usecols=col_list)\n",
        "df2 = pd.read_csv(DATA_PATH + dash + yellowTag + dash + 'yellow0_rhythm2.csv', usecols=col_list)\n",
        "df4 = pd.read_csv(DATA_PATH + dash + yellowTag + dash + 'yellow0_rhythm4.csv', usecols=col_list)\n",
        "df6 = pd.read_csv(DATA_PATH + dash + yellowTag + dash + 'yellow0_rythym6.csv', usecols=col_list)\n",
        "onset_list0 = df0[\"Onset\"].tolist()\n",
        "offset_list0 = df0[\"Offset\"].tolist()\n",
        "onset_list2 = df2[\"Onset\"].tolist()\n",
        "offset_list2 = df2[\"Offset\"].tolist()\n",
        "onset_list4 = df4[\"Onset\"].tolist()\n",
        "offset_list4 = df4[\"Offset\"].tolist()\n",
        "onset_list6 = df6[\"Onset\"].tolist()\n",
        "offset_list6 = df6[\"Offset\"].tolist()\n",
        "\n",
        "df1 = pd.read_csv(DATA_PATH + dash + yellowTag + dash + 'yellow0_rhythm1.csv', usecols=col_list)\n",
        "df3 = pd.read_csv(DATA_PATH + dash + yellowTag + dash + 'yellow0_rhythm3.csv', usecols=col_list)\n",
        "df5 = pd.read_csv(DATA_PATH + dash + yellowTag + dash + 'yellow0_rhythm5.csv', usecols=col_list)\n",
        "\n",
        "onset_list1 = df1[\"Onset\"].tolist()\n",
        "offset_list1 = df1[\"Offset\"].tolist()\n",
        "onset_list3 = df3[\"Onset\"].tolist()\n",
        "offset_list3 = df3[\"Offset\"].tolist()\n",
        "onset_list5 = df5[\"Onset\"].tolist()\n",
        "offset_list5 = df5[\"Offset\"].tolist()\n"
      ],
      "metadata": {
        "id": "QROst929CCDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(onset_list1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nghkAopqIlsy",
        "outputId": "a571e91f-e456-4152-d8ad-bdf85dd7adbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.11, 0.455, 0.795, 1.135, 1.475, 1.815, 2.155, 2.5, 2.84, 3.18, 3.52, 3.86, 4.2, 4.545, 4.885, 5.225, 5.565, 5.92, 6.25, 6.59, 6.93, 7.275, 7.615, 7.955, 8.295, 8.635, 8.99, 9.32, 9.66, 10.0, 10.34, 10.68, 11.02, 11.365, 11.705, 12.045, 12.39, 12.725, 13.07, 13.41, 13.755, 14.095, 14.43, 14.775, 15.12, 15.455, 15.795, 16.145, 16.48, 16.825, 17.165, 17.5, 17.84, 18.18, 18.52, 18.86, 19.2, 19.545, 19.885, 20.225, 20.565, 20.905, 21.25, 21.59, 21.93, 22.27, 22.61, 22.95, 23.295, 23.635, 23.975, 24.315, 24.655, 25.0, 25.34, 25.68, 26.02, 26.36, 26.7, 27.045, 27.385, 27.74, 28.07, 28.41, 28.75, 29.09, 29.43, 29.775, 30.115, 30.455, 30.795, 31.135, 31.49, 31.82, 32.16, 32.5, 32.84, 33.185, 33.525, 33.865, 34.205, 34.545, 34.89, 35.225, 35.57, 35.91, 36.25, 36.595, 36.93, 37.275, 37.62, 37.955, 38.3, 38.64, 38.975, 39.32, 39.66, 40.0, 40.34, 40.68, 41.02, 41.36, 41.7, 42.045, 42.385, 42.725, 43.065, 43.405, 43.75, 44.105, 44.43, 44.775, 45.115, 45.455, 45.795, 46.135, 46.49, 46.82, 47.16, 47.5, 47.84, 48.18, 48.525, 48.865, 49.205, 49.545, 49.885, 50.23, 50.57, 50.91, 51.25, 51.595, 51.93, 52.275, 52.62, 52.955, 53.295, 53.64, 53.975, 54.32, 54.66, 55.005, 55.34, 55.675, 56.02, 56.36, 56.7, 57.045, 57.385, 57.725, 58.065, 58.405, 58.75, 59.09, 59.43, 59.77, 60.11, 60.465, 60.795, 61.135, 61.49, 61.82, 62.16, 62.5, 62.84, 63.18, 63.525, 63.865, 64.205, 64.545, 64.885, 65.24, 65.565, 65.91, 66.25, 66.59, 66.935, 67.275, 67.62, 67.955, 68.295, 68.64, 68.98, 69.32, 69.66, 70.0, 70.345, 70.68, 71.025, 71.365, 71.7, 72.05, 72.385, 72.725, 73.065, 73.405, 73.75, 74.09, 74.43, 74.77, 75.11, 75.45, 75.795, 76.135]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "################################################ Statistics Column Headers  ################################################\n",
        "\n",
        "header2TF = [\"Student\", \"precision\", \"recall\", \"f_measure_value\", \"Onset ABS Mean\", \"Onset Mean\", \"Onset Std\",\n",
        "             \"Duration ABS Mean\", \"Duration Mean\", \"Duration Std\", \" finalMark\"]\n",
        "\n",
        "# Column names of the annotated columns in the rhythm files\n",
        "\n",
        "################################################ AUDIO PARAMETERS  ################################################\n",
        "\n",
        "fs = 44100\n",
        "windowSize = 1024\n",
        "hopSize = 512\n",
        "frameSize = windowSize\n",
        "\n",
        "#These are the different energy thresholds for the different Trinity tracks from  Stem 0 to Stem 5\n",
        "threshIndex = [0.049, 0.02, 0.1, 0.04505, 0.078, 0.1]\n",
        "matching_window_size = 0.02 # 0.0125 # MIREX reference"
      ],
      "metadata": {
        "id": "2432lHf5CZQM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def onset_SOP(audiofile):\n",
        "    #Detection function\n",
        "    fps = 200\n",
        "    sodf = madmom.features.onsets.SpectralOnsetProcessor('superflux', diff_frames=20)\n",
        "    sodf.processors[-1]  # doctest: +ELLIPSIS\n",
        "    det_function = sodf(audiofile, fps = fps)\n",
        "    det_function_norm = det_function/(max(det_function))\n",
        "\n",
        "    #Dynamic threashold\n",
        "    C_t = 0.99\n",
        "    H = 40\n",
        "    delta = 0.1\n",
        "\n",
        "    din_th = np.zeros(len(det_function_norm))\n",
        "    for m in range(H, len(det_function_norm)):\n",
        "        din_th[m] = C_t*np.median(det_function_norm[m-H:m+H])+delta\n",
        "\n",
        "    #Peak detection\n",
        "    peaks, _ = find_peaks(det_function_norm, distance=fps/10, height = din_th)  \n",
        "    onset_array = peaks/fps\n",
        "    return onset_array\n"
      ],
      "metadata": {
        "id": "fqt-k4VI5txv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def myOnsetEnergyChecker(x,theFrameSize,theHopSize,thresh):\n",
        "    \"\"\"\n",
        "    Calculates the energy of an input audio signal\n",
        "    The energy of a discrete time signal can be computed as:\n",
        "    begin{equation}\n",
        "        energy = \\sum_{n = 0}^{N-1} |x[n]|^2\n",
        "    end{equation}\n",
        "    where x[n] refers to the discrete time signal sample at index n\n",
        "    \"\"\"\n",
        "    fs=44100\n",
        "    NRG = [];\n",
        "    #Main windowing and feature extraction loop\n",
        "    for frame in FrameGenerator(x, frameSize = theFrameSize, hopSize = theHopSize):\n",
        "        NRG.append(Energy()(frame))\n",
        "    NRG = np.array(NRG)\n",
        "    NRG = NRG / np.max(NRG)\n",
        "    #Applying energy threshold to decide wave split boundaries\n",
        "    split_decision_func = np.zeros_like(NRG)\n",
        "    split_decision_func[NRG > thresh] = 1 \n",
        "    #Setting segment boundaries\n",
        "    #Inserting a zero at the beginning since we will decide the transitions using a diff function\n",
        "    split_decision_func = np.insert(split_decision_func, 0, 0)\n",
        "    diff_split_decision = np.diff(split_decision_func)\n",
        "    #Start indexes: transition from 0 to 1\n",
        "    start_indexes = np.nonzero(diff_split_decision > 0)[0] * theHopSize/fs\n",
        "    #Stop indexes: transition from 1 to 0\n",
        "    stop_indexes = np.nonzero(diff_split_decision < 0)[0] * theHopSize/fs\n",
        "    return (start_indexes, stop_indexes,split_decision_func,NRG)"
      ],
      "metadata": {
        "id": "Yw7JwqI5gJgJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pullEnergy(raw,startFrame,endFrame, th):\n",
        "    signal_snipbit = raw[startFrame:endFrame]\n",
        "    energy_signal_snipbit = Energy()(signal_snipbit) \n",
        "    ed = EffectiveDuration(thresholdRatio =th) (raw[startFrame:endFrame])\n",
        "    d = Duration() (raw[startFrame:endFrame])\n",
        "    return round(ed,3) , round(d,3)\n"
      ],
      "metadata": {
        "id": "6ZOZkOMhmttm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def wavread(filename):\n",
        "\t\"\"\"\n",
        "\tRead a sound file and convert it to a normalized floating point array\n",
        "\tfilename: name of file to read\n",
        "\treturns fs: sampling rate of file, x: floating point array\n",
        "\t\"\"\"\n",
        "\n",
        "\tif (os.path.isfile(filename) == False):                  # raise error if wrong input file\n",
        "\t\traise ValueError(\"Input file is wrong\")\n",
        "\n",
        "\tfs, x = read(filename)\n",
        "\n",
        "\tif (len(x.shape) !=1):                                   # raise error if more than one channel\n",
        "\t\traise ValueError(\"Audio file should be mono\")\n",
        "\n",
        "\tif (fs !=44100):                                         # raise error if more than one channel\n",
        "\t\traise ValueError(\"Sampling rate of input sound should be 44100\")\n",
        "\n",
        "\t#scale down and convert audio into floating point number in range of -1 to 1\n",
        "\tx = np.float32(x)/norm_fact[x.dtype.name]\n",
        "\treturn fs, x"
      ],
      "metadata": {
        "id": "BOj9y51eIlb1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def wavwrite(y, fs, filename):\n",
        "\t\"\"\"\n",
        "\tWrite a sound file from an array with the sound and the sampling rate\n",
        "\ty: floating point array of one dimension, fs: sampling rate\n",
        "\tfilename: name of file to create\n",
        "\t\"\"\"\n",
        "\n",
        "\tx = copy.deepcopy(y)                         # copy array\n",
        "\tx *= INT16_FAC                               # scaling floating point -1 to 1 range signal to int16 range\n",
        "\tx = np.int16(x)                              # converting to int16 type\n",
        "\twrite(filename, fs, x)"
      ],
      "metadata": {
        "id": "3Hc5GywCSJIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# E1 - 1.1: Complete the read_audio_samples() function\n",
        "\n",
        "def read_audio_samples(input_file, t1, t2):\n",
        "    \"\"\"Read num_samples samples from an audio file starting at sample first_sample\n",
        "    \n",
        "    Args:\n",
        "        input_file (str): path of a wav file      \n",
        "    \n",
        "    Returns:\n",
        "        np.array: numpy array containing the selected samples\n",
        "    \n",
        "    \"\"\"   \n",
        "    ### Your code here\n",
        "    _, x = wavread(input_file) \n",
        "    # really should be a assert here\n",
        "    fs = 44100\n",
        "    first_sample = int(t1 * fs)\n",
        "    last_sample = int(t2 * fs)\n",
        "    return x[first_sample:last_sample-1] # Decrement first sample by 1 to get correct array index."
      ],
      "metadata": {
        "id": "4xHc7_ClHou0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def call_sop(audio_file,file_suffix,i,th):\n",
        "    fs = 44100\n",
        "    raw = MonoLoader(filename = audio_file, sampleRate = fs)()\n",
        "    raw = raw / np.max(np.abs(raw))\n",
        "    #Get time position of last sample\n",
        "    last_sample = round((len(raw)-1)/44100,3)\n",
        "    # Save the IEC  onsets in a file for the stem\n",
        "    onsetStemSOP = onset_SOP(audio_file)\n",
        "    if (len(onsetStemSOP)==0):\n",
        "        print(\"===============WARNING: EMPTY ONSETS===============\")\n",
        "\n",
        "    onset_array = []\n",
        "    offset_array = []\n",
        "    dur_array = []\n",
        "    edur_array = []\n",
        "    index=0\n",
        "\n",
        "    while index < len(onsetStemSOP)-1:   #  This is like a hard code, we know thi is the greater value\n",
        "        startFrame = int( fs*(onsetStemSOP[index]))\n",
        "        endFrame =   int( fs*(onsetStemSOP[index+1]))\n",
        "        ed,d = pullEnergy(raw,startFrame,endFrame,th)\n",
        "        edur_array.append(ed)\n",
        "        dur_array.append(d)                   \n",
        "        ####################################     \n",
        "        onset_array.append(onsetStemSOP[index])\n",
        "        offset_array.append(onsetStemSOP[index+1])\n",
        "        edur_array.append(ed)\n",
        "        index+=1\n",
        "    onset_array.append(onsetStemSOP[index])\n",
        "\n",
        "    last_offset = last_sample\n",
        "    offset_array.append(last_offset)\n",
        "\n",
        "\n",
        "    last_dur= last_offset-onsetStemSOP[index]\n",
        "    edur_array.append(last_dur)\n",
        "    return (onset_array, offset_array,edur_array,dur_array)\n",
        "\n"
      ],
      "metadata": {
        "id": "PzJNjrIu8y5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "AEr91W6m9RI7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t_array = [0.0, 13.53, 89.95, 60.0 + 51.825, 120.0 + 51.79, 180.0 + 12.643,240.0 + 8.167,240.0 + 23.0]\n"
      ],
      "metadata": {
        "id": "sc4MWL2aLhKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#\n",
        "# Helper function of f_measure\n",
        "#\n",
        "def f_measure(precision, recall):\n",
        "    if precision == 0 and recall == 0:\n",
        "        return 0.0\n",
        "    return 2.0 * precision*recall / (precision + recall)\n",
        "#    \n",
        "# Helper function of evaluate accuracy\n",
        "#\n",
        "def evaluate_accuracy(gt_onsets, onsets, matching_window_size):\n",
        "    matching,_,_= match_events(\n",
        "        gt_onsets,\n",
        "        onsets,\n",
        "        matching_window_size)\n",
        "    precision = float(len(matching)) / len(onsets)\n",
        "    recall = float(len(matching)) / len(gt_onsets)\n",
        "    f_measure_value = f_measure(precision, recall)\n",
        "    return precision, recall, f_measure_value\n",
        "\n",
        "def match_rhythm(df, onsets, offsets, matching_window_size):\n",
        "    \"\"\"\n",
        "    Finds best matching pairs so\n",
        "       - distance between elements is no greater than matching_window_size\n",
        "       - sum of all distances is is minimized\n",
        "       - also returns the fidelity ( conformance to 100% hit notes)\n",
        "    \"\"\"\n",
        "    result = []\n",
        "    missing_onset_notes= 0\n",
        "    onset_deviation_array = []\n",
        "    offset_deviation_array = []\n",
        "    rhythm_deviation_array = []\n",
        "\n",
        "    gt_onsets = df[\"Onset\"].tolist()\n",
        "    gt_offsets = df[\"Offset\"].tolist()\n",
        "\n",
        "\n",
        "    m = scipy.spatial.distance_matrix([[x] for x in gt_onsets], [[x] for x in onsets])\n",
        "    # don't consider events which are out of matching window size\n",
        "    big_distance = 10 ** 6\n",
        "    m[m > matching_window_size] = big_distance\n",
        "\n",
        "    row_ons, col_ons = scipy.optimize.linear_sum_assignment(m)\n",
        "    jindex=-1\n",
        "    for (xn, yn) in zip(row_ons, col_ons):\n",
        "        jindex+=1\n",
        "        if abs((onsets[yn]) - gt_onsets[xn]) <= matching_window_size:\n",
        "            onset_deviation_array.append((onsets[yn]) - gt_onsets[xn]) \n",
        "            # We are within margin\n",
        "            # Check if Muted\n",
        "            if abs((offsets[yn]) - gt_offsets[xn]) <= matching_window_size*2:\n",
        "               offset_deviation_array.append(offsets[yn] - gt_offsets[xn])\n",
        "\n",
        "            #if (xn+1 <len (row_ons)):\n",
        "            #      offset_deviation_array.append(offsets[yn] - gt_onsets[xn+1])\n",
        "        else:\n",
        "            missing_onset_notes+=1\n",
        "    return onset_deviation_array,offset_deviation_array,missing_onset_notes\n",
        "\t\n",
        "# The match_events function returns results of matching pairs,deviations of thos pairs and the missing_notes\n",
        "def match_events(gt_onsets, onsets, matching_window_size):\n",
        "    \"\"\"\n",
        "    Finds best matching pairs so\n",
        "       - distance between elements is no greater than matching_window_size\n",
        "       - sum of all distances is minimized\n",
        "    \"\"\"\n",
        "    # In case of performance issues for big piecs,\n",
        "    # we could try to use simpler/faster local algorithm.\n",
        "    m = scipy.spatial.distance_matrix([[x] for x in gt_onsets], [[x] for x in onsets])\n",
        "    # don't consider events which are out of matching window size\n",
        "    big_distance = 10 ** 6\n",
        "    m[m > matching_window_size] = big_distance\n",
        "    \n",
        "    row_ind, col_ind = scipy.optimize.linear_sum_assignment(m)\n",
        "    result = []\n",
        "    missing_notes= 0\n",
        "    deviations = []\n",
        "    for (x, y) in zip(row_ind, col_ind):\n",
        "        if abs(onsets[y]-gt_onsets[x]) <= matching_window_size:\n",
        "            result.append((x, y))\n",
        "            deviations.append(gt_onsets[x] - onsets[y])\n",
        "        else:\n",
        "            missing_notes+=1\n",
        "    return result,deviations,missing_notes\n",
        "\n",
        "def hist_and_stats(deviations,title_text):\n",
        "    a = np.array(deviations)\n",
        "    #plt.title(title_text)\n",
        "    #plt.hist(a)\n",
        "    #plt.show()\n",
        "    m, s = mean(a), sqrt(mean(a*a))\n",
        "    #print(\"Mean: %f, Deviation from zero: %f\" %(m, s))\n",
        "    return m, s\n",
        "\n",
        "\n",
        "def aggregate_hist_and_stats(deviationArrays,title_text):\n",
        "    all_deviations = []\n",
        "    for d in deviationArrays:\n",
        "        all_deviations.extend(d)\n",
        "        # presentation of individual songs, if you need it\n",
        "        #hist_and_stats(onset_deviationsArray[i])\n",
        "    hist_and_stats(all_deviations,title_text)"
      ],
      "metadata": {
        "id": "LF9xy_hUCFU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qPeRPYYFKHzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while index < len(t_array)-1:\n",
        "   input_filename = yellowStemPrefix+fileSuffix\n",
        "   audio_piece = read_audio_samples(input_filename, t_array[index], t_array[index+1])\n",
        "   output_filename = yellowStemPrefix+'_'+str(index)+fileSuffix   \n",
        "   print(output_filename)\n",
        "   stem_file_array.append(output_filename)\n",
        "   wavwrite(audio_piece,44100,output_filename)\n",
        "   index = index+1"
      ],
      "metadata": {
        "id": "bm5VGfLf8oRD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(stem_file_array))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UiqdsoXu_Duj",
        "outputId": "9ada105c-ac23-4fb1-cd11-21760a43e1cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def call_sop_file(audio_file,file_suffix,i,th):\n",
        "    print(\"Calling SOP algorithm\")\n",
        "    fs = 44100\n",
        "    raw = MonoLoader(filename = audio_file, sampleRate = fs)()\n",
        "    raw = raw / np.max(np.abs(raw))\n",
        "    #Get time position of last sample\n",
        "    last_sample = round((len(raw)-1)/44100,3)\n",
        "    # Save the IEC  onsets in a file for the stem\n",
        "    onsetStemSOP = onset_SOP(audio_file)\n",
        "    if (len(onsetStemSOP)==0):\n",
        "        print(\"===============WARNING: EMPTY ONSETS===============\")\n",
        "    DPATH2= DATA_PATH + dash + yellowTag + dash\n",
        "    fname = DPATH2+'_onsets_'+str(i)+'.csv' \n",
        "    print(fname)\n",
        "    f1 = open(fname, \"w\")\n",
        "\n",
        "    onset_array = []\n",
        "    offset_array = []\n",
        "    dur_array = []\n",
        "    edur_array = []\n",
        "    index=0\n",
        "\n",
        "    while index < len(onsetStemSOP)-1:  \n",
        "        f1.write(str(onsetStemSOP[index]) )   \n",
        "        f1.write('\\r')   \n",
        "        startFrame = int( fs*(onsetStemSOP[index]))\n",
        "        endFrame =   int( fs*(onsetStemSOP[index+1]))\n",
        "        ed,d = pullEnergy(raw,startFrame,endFrame,th)\n",
        "        edur_array.append(ed)\n",
        "        dur_array.append(d)                   \n",
        "        ####################################     \n",
        "        onset_array.append(onsetStemSOP[index])\n",
        "        offset_array.append(onsetStemSOP[index+1])\n",
        "        edur_array.append(ed)\n",
        "        index+=1\n",
        "    f1.write(str(onsetStemSOP[index]) )   \n",
        "    f1.write('\\r')  \n",
        "    onset_array.append(onsetStemSOP[index])\n",
        "    last_offset = last_sample\n",
        "    offset_array.append(last_offset)\n",
        "    f1.write(str(last_offset) )   \n",
        "    f1.write('\\r') \n",
        "\n",
        "\n",
        "    last_dur= last_offset-onsetStemSOP[index]\n",
        "    edur_array.append(last_dur)\n",
        "    f1.close    \n",
        "    return (onset_array, offset_array,edur_array,dur_array)\n"
      ],
      "metadata": {
        "id": "WJwveU_EBIGw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = 0 \n",
        "while index < len(stem_file_array):\n",
        "   input_filename = stem_file_array[index] \n",
        "   onset_array,offset_array, edur,_ = call_sop_file(input_filename,fileSuffix,index,0)\n",
        "   index = index+1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VrvpplAL7JSp",
        "outputId": "e61e1d63-d19b-433f-c517-449eccfe8e4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calling SOP algorithm\n",
            "drive/MyDrive/Thesis/Experiments/data/yellow/_onsets_0.csv\n",
            "Calling SOP algorithm\n",
            "drive/MyDrive/Thesis/Experiments/data/yellow/_onsets_1.csv\n",
            "Calling SOP algorithm\n",
            "drive/MyDrive/Thesis/Experiments/data/yellow/_onsets_2.csv\n",
            "Calling SOP algorithm\n",
            "drive/MyDrive/Thesis/Experiments/data/yellow/_onsets_3.csv\n",
            "Calling SOP algorithm\n",
            "drive/MyDrive/Thesis/Experiments/data/yellow/_onsets_4.csv\n",
            "Calling SOP algorithm\n",
            "drive/MyDrive/Thesis/Experiments/data/yellow/_onsets_5.csv\n",
            "Calling SOP algorithm\n",
            "drive/MyDrive/Thesis/Experiments/data/yellow/_onsets_6.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "skiptime = 0.033\n",
        "print(len(t_array))\n",
        "print(t_array)\n"
      ],
      "metadata": {
        "id": "lqnbSi2nMyft",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25408e0e-b840-43a8-e671-e6d1df4af0fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n",
            "[0.0, 13.53, 89.95, 111.825, 171.79, 192.643, 248.167, 263.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "student_index = 13\n",
        "MAX_STUDENTS= len(studentFilenames)\n",
        "student_file_array = []\n",
        "while student_index < len(studentFilenames):\n",
        "    section_index = 0 \n",
        "    fname = studentFilenames[student_index]+fileSuffix \n",
        "    print(fname)\n",
        "    while section_index < len(t_array)-1:\n",
        "      audio_piece = read_audio_samples(fname,t_array[section_index], t_array[section_index+1])\n",
        "      fname2= studentFilenames[student_index]+'_'+str(section_index)+fileSuffix\n",
        "      print(fname2)\n",
        "      wavwrite(audio_piece,44100,fname2)\n",
        "      section_index = section_index+1\n",
        "    student_index+=1\n",
        "print(student_file_array)"
      ],
      "metadata": {
        "id": "QiwE-uNrcYl_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "th = 0.05\n",
        "IEC_threshold = 0.452\n",
        "student_file_array = []\n",
        "student_index=0\n",
        "fname = studentFilenames[0]+fileSuffix \n"
      ],
      "metadata": {
        "id": "irbSfQGM1rzH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "section_index = 0\n",
        "fname2= studentFilenames[0]+'_'+str(section_index)+fileSuffix\n",
        "\n",
        "_ ,  x = wavread(fname2) \n",
        "\n",
        "myOnsetEnergyChecker\n",
        "start_indexes, stop_indexes,split_decision_func,NRG = myOnsetEnergyChecker(x,frameSize,hopSize, IEC_threshold)  \n",
        "print(start_indexes,stop_indexes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7m8b_Rjgi6z",
        "outputId": "fdcc82e2-c886-4f03-a9a6-ff352be02a73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 2.73995465  2.92571429  5.4799093   5.72371882  5.77015873  8.21986395\n",
            "  8.35918367  8.44045351  8.48689342  8.53333333 10.95981859 11.01786848] [ 2.90249433  2.93732426  5.70049887  5.7353288   5.78176871  8.3475737\n",
            "  8.42884354  8.46367347  8.51011338  8.54494331 10.99464853 11.02947846]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls drive/MyDrive/Thesis/Experiments/audio/yellow/1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4uIrVCigHKV",
        "outputId": "2733b647-eb67-430d-83db-917607d6ec13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y1_0.wav  y1_1.wav  y1_2.wav  y1_3.wav\ty1_4.wav  y1_5.wav  y1_6.wav  y1.wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(studentFilenames)"
      ],
      "metadata": {
        "id": "P1aQgpgGof3E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16f565cb-4f5e-4b0f-eab8-b8fccdb6eaf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "th = 0.05\n",
        "IEC_threshold = 0.0452\n",
        "student_file_array = []\n",
        "total_sprecision_array = []\n",
        "total_srecall_array   = []\n",
        "total_sf_measure_value_array = []\n",
        "total_sonset_deviationsArray=[]\n",
        "total_soffset_deviationsArray=[]\n",
        "matching_window_size = 0.025\n",
        "student_index=0\n",
        "while student_index < len(studentFilenames):\n",
        "    section_index = 0 \n",
        "    sprecision_array = []\n",
        "    srecall_array   = []\n",
        "    sf_measure_value_array = []\n",
        "    sonset_deviationsArray=[]\n",
        "    soffset_deviationsArray=[]\n",
        "    while section_index <  len(t_array)-1:\n",
        "       fname2= studentFilenames[student_index]+'_'+str(section_index)+fileSuffix\n",
        "       _ ,  x = wavread(fname2)   \n",
        "       if (section_index==0) :     \n",
        "           #onset_array,offset_array,_,edur = myOnsetEnergyChecker(x,frameSize,hopSize, IEC_threshold)  \n",
        "           onset_array,offset_array, edur,_ = call_sop(fname2,fileSuffix,section_index,th)\n",
        "           sprecision, srecall, sf_measure_value = evaluate_accuracy(onset_list0, onset_array, matching_window_size)\n",
        "           sonset_deviations,soffset_deviations, _ = match_rhythm(df0,onset_array,offset_array,matching_window_size)\n",
        "           print(sonset_deviations)\n",
        "           print(student_index,section_index,\"   sprecision, srecall, sf_measure_value Part\" , section_index)\n",
        "           print(\"   \", round(sprecision,3), round(srecall,3),  round(sf_measure_value,3))\n",
        "       elif (section_index==2) :\n",
        "           #onset_array,offset_array,_,edur = myOnsetEnergyChecker(x,frameSize,hopSize, IEC_threshold)\n",
        "           onset_array,offset_array, edur,_ = call_sop(fname2,fileSuffix,section_index,th)\n",
        "           sprecision, srecall, sf_measure_value = evaluate_accuracy(onset_list2, onset_array, matching_window_size)\n",
        "           sonset_deviations,soffset_deviations, _ = match_rhythm(df2,onset_array,offset_array,matching_window_size)\n",
        "           #print(student_index,section_index,\"   sprecision, srecall, sf_measure_value Part\" , section_index)\n",
        "           #print(\"   \", round(sprecision,3), round(srecall,3), round(sf_measure_value,3))\n",
        "       elif (section_index==4) :\n",
        "           #onset_array,offset_array,_,edur = myOnsetEnergyChecker(x,frameSize,hopSize, IEC_threshold)\n",
        "           onset_array,offset_array, edur,_ = call_sop(fname2,fileSuffix,section_index,th)\n",
        "           sprecision, srecall, sf_measure_value = evaluate_accuracy(onset_list4, onset_array, matching_window_size)\n",
        "           sonset_deviations,soffset_deviations, _ = match_rhythm(df4,onset_array,offset_array,matching_window_size)\n",
        "           #print(student_index,section_index,\"   sprecision, srecall, sf_measure_value Part\" , section_index)\n",
        "           #print(\"   \", round(sprecision,3), round(srecall,3), round(sf_measure_value,3))\n",
        "       elif (section_index==6) :\n",
        "           #onset_array,offset_array,_,edur = myOnsetEnergyChecker(x,frameSize,hopSize, IEC_threshold)\n",
        "           onset_array,offset_array, edur,_ = call_sop(fname2,fileSuffix,section_index,th)\n",
        "           sprecision, srecall, sf_measure_value = evaluate_accuracy(onset_list6, onset_array, matching_window_size)\n",
        "           sonset_deviations,soffset_deviations, _ = match_rhythm(df6,onset_array,offset_array,matching_window_size)\n",
        "           #print(student_index,section_index,\"   sprecision, srecall, sf_measure_value Part\" , section_index)\n",
        "           #print(\"   \", round(sprecision,3), round(srecall,3),  round(sf_measure_value,3))\n",
        "       elif (section_index==1) :\n",
        "           onset_array,offset_array, edur,_ = call_sop(fname2,fileSuffix,section_index,th)\n",
        "           sprecision, srecall, sf_measure_value = evaluate_accuracy(onset_list1, onset_array, matching_window_size)\n",
        "           sonset_deviations,soffset_deviations, _ = match_rhythm(df1,onset_array,offset_array,matching_window_size)\n",
        "           print(student_index,section_index,\"   sprecision, srecall, sf_measure_value Part\" , section_index)\n",
        "           print(\"   \", round(sprecision,3), round(srecall,3),  round(sf_measure_value,3))\n",
        "       elif (section_index==3) :\n",
        "           onset_array,offset_array, edur,_ = call_sop(fname2,fileSuffix,section_index,th)\n",
        "           sprecision, srecall, sf_measure_value = evaluate_accuracy(onset_list3, onset_array, matching_window_size)\n",
        "           sonset_deviations,soffset_deviations, _ = match_rhythm(df3,onset_array,offset_array,matching_window_size)\n",
        "           print(student_index,section_index,\"   sprecision, srecall, sf_measure_value Part\" , section_index)\n",
        "           print(\"   \", round(sprecision,3), round(srecall,3),  round(sf_measure_value,3))\n",
        "       elif (section_index==5) :\n",
        "           onset_array,offset_array, edur,_ = call_sop(fname2,fileSuffix,section_index,th)\n",
        "           sprecision, srecall, sf_measure_value = evaluate_accuracy(onset_list5, onset_array, matching_window_size)\n",
        "           sonset_deviations,soffset_deviations, _ = match_rhythm(df5,onset_array,offset_array,matching_window_size)\n",
        "           print(student_index,section_index,\"   sprecision, srecall, sf_measure_value Part\" , section_index)\n",
        "           print(\"   \", round(sprecision,3), round(srecall,3),  round(sf_measure_value,3))           \n",
        "       # Append Student onset/offsets\n",
        "       sprecision_array.append(sprecision)\n",
        "       srecall_array.append(srecall)\n",
        "       sf_measure_value_array.append(sf_measure_value)\n",
        "       sonset_deviationsArray.append(sonset_deviations)\n",
        "       soffset_deviationsArray.append(soffset_deviations)\n",
        "       section_index+=1\n",
        "    total_sprecision_array.append(sprecision_array)\n",
        "    total_srecall_array.append(srecall_array)\n",
        "    total_sf_measure_value_array.append(sf_measure_value_array)\n",
        "    total_sonset_deviationsArray.append(sonset_deviationsArray)\n",
        "    total_soffset_deviationsArray.append(soffset_deviationsArray)       \n",
        "    print()\n",
        "    student_index+=1\n",
        "    print(student_index, \" \", section_index)"
      ],
      "metadata": {
        "id": "ILZazfc-Tpdk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "906df0c5-8e72-4b1f-e8b5-46781ae0e4a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.009999999999999787, 0.009999999999999787, 0.009999999999999787, 0.015000000000000568]\n",
            "0 0    sprecision, srecall, sf_measure_value Part 0\n",
            "    0.667 1.0 0.8\n",
            "0 1    sprecision, srecall, sf_measure_value Part 1\n",
            "    0.139 0.125 0.131\n",
            "0 3    sprecision, srecall, sf_measure_value Part 3\n",
            "    0.184 0.186 0.185\n",
            "0 5    sprecision, srecall, sf_measure_value Part 5\n",
            "    0.134 0.137 0.135\n",
            "\n",
            "1   7\n",
            "[-0.02000000000000135]\n",
            "1 0    sprecision, srecall, sf_measure_value Part 0\n",
            "    0.167 0.25 0.2\n",
            "1 1    sprecision, srecall, sf_measure_value Part 1\n",
            "    0.546 0.5 0.522\n",
            "1 3    sprecision, srecall, sf_measure_value Part 3\n",
            "    0.372 0.379 0.375\n",
            "1 5    sprecision, srecall, sf_measure_value Part 5\n",
            "    0.307 0.311 0.309\n",
            "\n",
            "2   7\n",
            "[-0.020000000000000018, 0.009999999999999787]\n",
            "2 0    sprecision, srecall, sf_measure_value Part 0\n",
            "    0.4 0.5 0.444\n",
            "2 1    sprecision, srecall, sf_measure_value Part 1\n",
            "    0.295 0.299 0.297\n",
            "2 3    sprecision, srecall, sf_measure_value Part 3\n",
            "    0.278 0.282 0.28\n",
            "2 5    sprecision, srecall, sf_measure_value Part 5\n",
            "    0.331 0.348 0.339\n",
            "\n",
            "3   7\n",
            "[]\n",
            "3 0    sprecision, srecall, sf_measure_value Part 0\n",
            "    0.0 0.0 0.0\n",
            "3 1    sprecision, srecall, sf_measure_value Part 1\n",
            "    0.039 0.04 0.04\n",
            "3 3    sprecision, srecall, sf_measure_value Part 3\n",
            "    0.034 0.034 0.034\n",
            "3 5    sprecision, srecall, sf_measure_value Part 5\n",
            "    0.041 0.043 0.042\n",
            "\n",
            "4   7\n",
            "[-0.015000000000000124, 0.004999999999999893]\n",
            "4 0    sprecision, srecall, sf_measure_value Part 0\n",
            "    0.333 0.5 0.4\n",
            "4 1    sprecision, srecall, sf_measure_value Part 1\n",
            "    0.509 0.5 0.505\n",
            "4 3    sprecision, srecall, sf_measure_value Part 3\n",
            "    0.413 0.418 0.416\n",
            "4 5    sprecision, srecall, sf_measure_value Part 5\n",
            "    0.41 0.422 0.416\n",
            "\n",
            "5   7\n",
            "[0.020000000000000018, 0.01499999999999968, -0.02000000000000135, 0.009999999999999787]\n",
            "5 0    sprecision, srecall, sf_measure_value Part 0\n",
            "    0.667 1.0 0.8\n",
            "5 1    sprecision, srecall, sf_measure_value Part 1\n",
            "    0.267 0.263 0.265\n",
            "5 3    sprecision, srecall, sf_measure_value Part 3\n",
            "    0.283 0.305 0.293\n",
            "5 5    sprecision, srecall, sf_measure_value Part 5\n",
            "    0.143 0.155 0.149\n",
            "\n",
            "6   7\n",
            "[-0.015000000000000124, 0.004999999999999005]\n",
            "6 0    sprecision, srecall, sf_measure_value Part 0\n",
            "    0.333 0.5 0.4\n",
            "6 1    sprecision, srecall, sf_measure_value Part 1\n",
            "    0.242 0.29 0.264\n",
            "6 3    sprecision, srecall, sf_measure_value Part 3\n",
            "    0.249 0.277 0.262\n",
            "6 5    sprecision, srecall, sf_measure_value Part 5\n",
            "    0.144 0.161 0.152\n",
            "\n",
            "7   7\n",
            "[-0.004999999999999893, 0.004999999999999005]\n",
            "7 0    sprecision, srecall, sf_measure_value Part 0\n",
            "    0.4 0.5 0.444\n",
            "7 1    sprecision, srecall, sf_measure_value Part 1\n",
            "    0.218 0.228 0.223\n",
            "7 3    sprecision, srecall, sf_measure_value Part 3\n",
            "    0.326 0.328 0.327\n",
            "7 5    sprecision, srecall, sf_measure_value Part 5\n",
            "    0.266 0.261 0.263\n",
            "\n",
            "8   7\n",
            "[0.0, 0.019999999999999574, -0.015000000000000568]\n",
            "8 0    sprecision, srecall, sf_measure_value Part 0\n",
            "    0.5 0.75 0.6\n",
            "8 1    sprecision, srecall, sf_measure_value Part 1\n",
            "    0.116 0.125 0.12\n",
            "8 3    sprecision, srecall, sf_measure_value Part 3\n",
            "    0.185 0.226 0.204\n",
            "8 5    sprecision, srecall, sf_measure_value Part 5\n",
            "    0.152 0.161 0.157\n",
            "\n",
            "9   7\n",
            "[0.010000000000000231, 0.004999999999999893]\n",
            "9 0    sprecision, srecall, sf_measure_value Part 0\n",
            "    0.333 0.5 0.4\n",
            "9 1    sprecision, srecall, sf_measure_value Part 1\n",
            "    0.136 0.143 0.139\n",
            "9 3    sprecision, srecall, sf_measure_value Part 3\n",
            "    0.17 0.175 0.173\n",
            "9 5    sprecision, srecall, sf_measure_value Part 5\n",
            "    0.138 0.143 0.14\n",
            "\n",
            "10   7\n",
            "[0.019999999999999574, -0.02000000000000135]\n",
            "10 0    sprecision, srecall, sf_measure_value Part 0\n",
            "    0.286 0.5 0.364\n",
            "10 1    sprecision, srecall, sf_measure_value Part 1\n",
            "    0.441 0.438 0.439\n",
            "10 3    sprecision, srecall, sf_measure_value Part 3\n",
            "    0.357 0.373 0.365\n",
            "10 5    sprecision, srecall, sf_measure_value Part 5\n",
            "    0.395 0.422 0.408\n",
            "\n",
            "11   7\n",
            "[-0.009999999999999787, -0.009999999999999787]\n",
            "11 0    sprecision, srecall, sf_measure_value Part 0\n",
            "    0.333 0.5 0.4\n",
            "11 1    sprecision, srecall, sf_measure_value Part 1\n",
            "    0.044 0.045 0.044\n",
            "11 3    sprecision, srecall, sf_measure_value Part 3\n",
            "    0.09 0.096 0.093\n",
            "11 5    sprecision, srecall, sf_measure_value Part 5\n",
            "    0.023 0.025 0.024\n",
            "\n",
            "12   7\n",
            "[0.010000000000000231, -0.01499999999999968, -0.015000000000000568]\n",
            "12 0    sprecision, srecall, sf_measure_value Part 0\n",
            "    0.5 0.75 0.6\n",
            "12 1    sprecision, srecall, sf_measure_value Part 1\n",
            "    0.055 0.058 0.057\n",
            "12 3    sprecision, srecall, sf_measure_value Part 3\n",
            "    0.061 0.062 0.062\n",
            "12 5    sprecision, srecall, sf_measure_value Part 5\n",
            "    0.06 0.062 0.061\n",
            "\n",
            "13   7\n",
            "[]\n",
            "13 0    sprecision, srecall, sf_measure_value Part 0\n",
            "    0.0 0.0 0.0\n",
            "13 1    sprecision, srecall, sf_measure_value Part 1\n",
            "    0.458 0.317 0.375\n",
            "13 3    sprecision, srecall, sf_measure_value Part 3\n",
            "    0.357 0.26 0.301\n",
            "13 5    sprecision, srecall, sf_measure_value Part 5\n",
            "    0.436 0.298 0.354\n",
            "\n",
            "14   7\n",
            "[0.020000000000000018, 0.009999999999999787, 0.004999999999999005]\n",
            "14 0    sprecision, srecall, sf_measure_value Part 0\n",
            "    0.5 0.75 0.6\n",
            "14 1    sprecision, srecall, sf_measure_value Part 1\n",
            "    0.494 0.344 0.405\n",
            "14 3    sprecision, srecall, sf_measure_value Part 3\n",
            "    0.397 0.401 0.399\n",
            "14 5    sprecision, srecall, sf_measure_value Part 5\n",
            "    0.418 0.429 0.423\n",
            "\n",
            "15   7\n",
            "[0.020000000000000018, -0.005000000000000782]\n",
            "15 0    sprecision, srecall, sf_measure_value Part 0\n",
            "    0.333 0.5 0.4\n",
            "15 1    sprecision, srecall, sf_measure_value Part 1\n",
            "    0.394 0.375 0.384\n",
            "15 3    sprecision, srecall, sf_measure_value Part 3\n",
            "    0.404 0.39 0.397\n",
            "15 5    sprecision, srecall, sf_measure_value Part 5\n",
            "    0.247 0.255 0.251\n",
            "\n",
            "16   7\n",
            "[]\n",
            "16 0    sprecision, srecall, sf_measure_value Part 0\n",
            "    0.0 0.0 0.0\n",
            "16 1    sprecision, srecall, sf_measure_value Part 1\n",
            "    0.655 0.643 0.649\n",
            "16 3    sprecision, srecall, sf_measure_value Part 3\n",
            "    0.564 0.65 0.604\n",
            "16 5    sprecision, srecall, sf_measure_value Part 5\n",
            "    0.619 0.646 0.632\n",
            "\n",
            "17   7\n",
            "[0.020000000000000018, 0.0]\n",
            "17 0    sprecision, srecall, sf_measure_value Part 0\n",
            "    0.5 0.5 0.5\n",
            "17 1    sprecision, srecall, sf_measure_value Part 1\n",
            "    0.439 0.464 0.451\n",
            "17 3    sprecision, srecall, sf_measure_value Part 3\n",
            "    0.431 0.458 0.444\n",
            "17 5    sprecision, srecall, sf_measure_value Part 5\n",
            "    0.244 0.273 0.258\n",
            "\n",
            "18   7\n",
            "[-0.004999999999999893, 0.015000000000000568]\n",
            "18 0    sprecision, srecall, sf_measure_value Part 0\n",
            "    0.333 0.5 0.4\n",
            "18 1    sprecision, srecall, sf_measure_value Part 1\n",
            "    0.043 0.045 0.044\n",
            "18 3    sprecision, srecall, sf_measure_value Part 3\n",
            "    0.065 0.068 0.066\n",
            "18 5    sprecision, srecall, sf_measure_value Part 5\n",
            "    0.118 0.124 0.121\n",
            "\n",
            "19   7\n",
            "[0.019999999999999574, 0.0]\n",
            "19 0    sprecision, srecall, sf_measure_value Part 0\n",
            "    0.5 0.5 0.5\n",
            "19 1    sprecision, srecall, sf_measure_value Part 1\n",
            "    0.427 0.446 0.437\n",
            "19 3    sprecision, srecall, sf_measure_value Part 3\n",
            "    0.414 0.424 0.419\n",
            "19 5    sprecision, srecall, sf_measure_value Part 5\n",
            "    0.38 0.391 0.385\n",
            "\n",
            "20   7\n",
            "[-0.02499999999999991, -0.020000000000000462, 0.004999999999999005, 0.009999999999999787]\n",
            "20 0    sprecision, srecall, sf_measure_value Part 0\n",
            "    0.667 1.0 0.8\n",
            "20 1    sprecision, srecall, sf_measure_value Part 1\n",
            "    0.25 0.254 0.252\n",
            "20 3    sprecision, srecall, sf_measure_value Part 3\n",
            "    0.31 0.328 0.319\n",
            "20 5    sprecision, srecall, sf_measure_value Part 5\n",
            "    0.189 0.193 0.191\n",
            "\n",
            "21   7\n",
            "[0.015000000000000124, 0.0, 0.004999999999999005, 0.004999999999999005]\n",
            "21 0    sprecision, srecall, sf_measure_value Part 0\n",
            "    0.8 1.0 0.889\n",
            "21 1    sprecision, srecall, sf_measure_value Part 1\n",
            "    0.668 0.701 0.684\n",
            "21 3    sprecision, srecall, sf_measure_value Part 3\n",
            "    0.67 0.678 0.674\n",
            "21 5    sprecision, srecall, sf_measure_value Part 5\n",
            "    0.69 0.72 0.705\n",
            "\n",
            "22   7\n",
            "[-0.009999999999999787]\n",
            "22 0    sprecision, srecall, sf_measure_value Part 0\n",
            "    0.167 0.25 0.2\n",
            "22 1    sprecision, srecall, sf_measure_value Part 1\n",
            "    0.699 0.705 0.702\n",
            "22 3    sprecision, srecall, sf_measure_value Part 3\n",
            "    0.706 0.718 0.711\n",
            "22 5    sprecision, srecall, sf_measure_value Part 5\n",
            "    0.671 0.708 0.689\n",
            "\n",
            "23   7\n",
            "[0.020000000000000018, 0.01499999999999968, 0.0, 0.019999999999999574]\n",
            "23 0    sprecision, srecall, sf_measure_value Part 0\n",
            "    0.4 1.0 0.571\n",
            "23 1    sprecision, srecall, sf_measure_value Part 1\n",
            "    0.627 0.652 0.639\n",
            "23 3    sprecision, srecall, sf_measure_value Part 3\n",
            "    0.663 0.701 0.681\n",
            "23 5    sprecision, srecall, sf_measure_value Part 5\n",
            "    0.594 0.627 0.61\n",
            "\n",
            "24   7\n",
            "[0.0, 0.0]\n",
            "24 0    sprecision, srecall, sf_measure_value Part 0\n",
            "    0.2 0.5 0.286\n",
            "24 1    sprecision, srecall, sf_measure_value Part 1\n",
            "    0.154 0.156 0.155\n",
            "24 3    sprecision, srecall, sf_measure_value Part 3\n",
            "    0.186 0.203 0.194\n",
            "24 5    sprecision, srecall, sf_measure_value Part 5\n",
            "    0.259 0.267 0.263\n",
            "\n",
            "25   7\n",
            "[]\n",
            "25 0    sprecision, srecall, sf_measure_value Part 0\n",
            "    0.0 0.0 0.0\n",
            "25 1    sprecision, srecall, sf_measure_value Part 1\n",
            "    0.541 0.558 0.549\n",
            "25 3    sprecision, srecall, sf_measure_value Part 3\n",
            "    0.448 0.418 0.433\n",
            "25 5    sprecision, srecall, sf_measure_value Part 5\n",
            "    0.46 0.497 0.478\n",
            "\n",
            "26   7\n",
            "[0.02499999999999991, 0.019999999999999574]\n",
            "26 0    sprecision, srecall, sf_measure_value Part 0\n",
            "    0.2 0.5 0.286\n",
            "26 1    sprecision, srecall, sf_measure_value Part 1\n",
            "    0.211 0.21 0.21\n",
            "26 3    sprecision, srecall, sf_measure_value Part 3\n",
            "    0.204 0.186 0.195\n",
            "26 5    sprecision, srecall, sf_measure_value Part 5\n",
            "    0.188 0.186 0.187\n",
            "\n",
            "27   7\n",
            "[0.0, 0.004999999999999893, 0.019999999999999574]\n",
            "27 0    sprecision, srecall, sf_measure_value Part 0\n",
            "    0.5 0.75 0.6\n",
            "27 1    sprecision, srecall, sf_measure_value Part 1\n",
            "    0.233 0.237 0.235\n",
            "27 3    sprecision, srecall, sf_measure_value Part 3\n",
            "    0.177 0.158 0.167\n",
            "27 5    sprecision, srecall, sf_measure_value Part 5\n",
            "    0.076 0.081 0.078\n",
            "\n",
            "28   7\n",
            "[0.004999999999999005]\n",
            "28 0    sprecision, srecall, sf_measure_value Part 0\n",
            "    0.167 0.25 0.2\n",
            "28 1    sprecision, srecall, sf_measure_value Part 1\n",
            "    0.503 0.433 0.465\n",
            "28 3    sprecision, srecall, sf_measure_value Part 3\n",
            "    0.538 0.514 0.526\n",
            "28 5    sprecision, srecall, sf_measure_value Part 5\n",
            "    0.329 0.422 0.37\n",
            "\n",
            "29   7\n",
            "[0.020000000000000018, -0.009999999999999787, 0.019999999999999574]\n",
            "29 0    sprecision, srecall, sf_measure_value Part 0\n",
            "    0.5 0.75 0.6\n",
            "29 1    sprecision, srecall, sf_measure_value Part 1\n",
            "    0.226 0.232 0.229\n",
            "29 3    sprecision, srecall, sf_measure_value Part 3\n",
            "    0.406 0.39 0.398\n",
            "29 5    sprecision, srecall, sf_measure_value Part 5\n",
            "    0.247 0.273 0.26\n",
            "\n",
            "30   7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(total_sonset_deviationsArray[0]))\n",
        "print(len(total_soffset_deviationsArray[0]))\n",
        "print(len(total_sonset_deviationsArray[2]))\n",
        "print(len(total_sonset_deviationsArray[3]))\n",
        "print(len(total_sonset_deviationsArray[4]))\n",
        "print(len(total_sonset_deviationsArray[5]))\n",
        "print(len(total_sonset_deviationsArray[17]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TvsURcRJeiWy",
        "outputId": "60348f9f-108a-4013-9560-a1806d2ed9e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "student_index=0  \n",
        "studentStatisticsArray= []\n",
        "studentStatistics = []\n",
        "total_onset_amean = []\n",
        "total_onset_mean = []\n",
        "total_onset_std= []\n",
        "total_offset_amean = []\n",
        "total_offset_mean = []\n",
        "total_offset_std= []\n",
        "i=0\n",
        "while i < len(studentFilenames): # I is the Student Index\n",
        "    onset_amean = []\n",
        "    onset_mean = []\n",
        "    onset_std= []\n",
        "    offset_amean = []\n",
        "    offset_mean = []\n",
        "    offset_std= []\n",
        "    j=0\n",
        "    while j <  len(t_array)-1: # J is ithe section index\n",
        "           print(a)\n",
        "       a = np.array(total_sonset_deviationsArray[i][j])\n",
        "       print(a)\n",
        "       onset_m, onset_s = mean(a), sqrt(mean(a*a))\n",
        "       onset_am = mean(abs(a))\n",
        "       onset_summary = \"Onset ABS  Mean: %f,Onset Mean: %f, Std. Dev. from 0:%f\" %(onset_am,onset_m, onset_s)\n",
        "       title =   \"Student: \" + str(i)+ \"section: \"+ str(j)\n",
        "       onset_mean.append(onset_m)\n",
        "       onset_amean.append(onset_am)\n",
        "       onset_std.append(onset_s)\n",
        "       if ((i>19) and (i<22)) and ((j==0) or (j==6)):\n",
        "          plt.subplot(2,2,1)\n",
        "          plt.title(title)\n",
        "          plt.figure(1, figsize=(9.5, 6))\n",
        "          plt.hist(a)\n",
        "          print(onset_summary)\n",
        "\n",
        "       a = np.array(total_soffset_deviationsArray[i][j])\n",
        "       offset_m, offset_s = mean(a), sqrt(mean(a*a))\n",
        "       offset_am = mean(abs(a))\n",
        "       offset_summary = \"Offset ABS  Mean: %f,Offset Mean: %f, Std. Dev. from 0:%f\" %(onset_am,onset_m, onset_s)\n",
        "       title =   \"Student: \" + str(i)+ \"section: \"+ str(j)\n",
        "       offset_mean.append(offset_m)\n",
        "       offset_amean.append(offset_am)\n",
        "       offset_std.append(offset_s)\n",
        "       if (i==2) and (j==0):\n",
        "          plt.subplot(2,2,2)\n",
        "          plt.title(title)\n",
        "          plt.figure(1, figsize=(9.5, 6))\n",
        "          plt.hist(a)\n",
        "          print(offset_summary)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WdslYaFA1o37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "outputId": "4108ae30-001e-4f58-ae03-7614397608c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.010000000000000002\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-673a7b63f569>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m        \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_sonset_deviationsArray\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m        \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m        \u001b[0monset_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monset_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m        \u001b[0monset_am\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m        \u001b[0monset_summary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Onset ABS  Mean: %f,Onset Mean: %f, Std. Dev. from 0:%f\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monset_am\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0monset_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monset_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/statistics.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    304\u001b[0m     \u001b[0mIf\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mempty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStatisticsError\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mraised\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m     \"\"\"\n\u001b[0;32m--> 306\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: iteration over a 0-d array"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv  \n",
        "def statisticsGenerator(deviationsArray1,deviationsArray2,title_text1,title_text2,df):\n",
        "  header = [\"Student\",\"precision\",\"recall\",\"f_measure_value\",\"Onset ABS Mean\",\"Onset Mean\",\"Onset Std\",\"Duration ABS Mean\",\"Duration Mean\",\"Duration Std\",\"YousicianMark\"]\n",
        "\n",
        "  studentStatisticsArray= []\n",
        "  idx = df.index\n",
        "  number_of_rows = len(idx)\n",
        "\n",
        "  studentStatistics = []\n",
        "  onset_amean = []\n",
        "  onset_mean = []\n",
        "  onset_std= []\n",
        "\n",
        "  duration_amean = []\n",
        "  duration_mean = []\n",
        "  duration_std= []\n",
        "  list0 = df[\"YousicianMark\"].tolist()  \n",
        "  listp = df[\"precision\"].tolist()  \n",
        "  listr = df[\"recall\"].tolist()  \n",
        "  listf = df[\"f_measure_value\"].tolist()  \n",
        " \n",
        "  k=0\n",
        "\n",
        "  for k in range(number_of_rows):\n",
        "    print(\"===================================\")\n",
        "    studentStatistics.append(str(k+1))\n",
        "    student_stats1 = [] # onsets\n",
        "    student_stats2 = [] # durations\n",
        "\n",
        "    plt.subplot(2,2,1)\n",
        "    a = np.array(deviationsArray1[k])\n",
        "    onset_m, onset_s = mean(a), sqrt(mean(a*a))\n",
        "    onset_am= mean(abs(a))\n",
        "    onset_summary= \"Onset ABS  Mean: %f,Onset Mean: %f, Std. Dev. from 0:%f\" %(onset_am,onset_m, onset_s)\n",
        "    title =   \"Student \" + str(k)+ title_text1\n",
        "\n",
        "\n",
        "    onset_mean.append(onset_m)\n",
        "    onset_amean.append(onset_am)\n",
        "    onset_std.append(onset_s)\n",
        "\n",
        "    plt.title(title)\n",
        "    plt.figure(1, figsize=(9.5, 6))\n",
        "    plt.hist(a)\n",
        "\n",
        "    plt.subplot(2,2,2)\n",
        "    a = np.array(deviationsArray2[k])\n",
        "    duration_m, duration_s = mean(a), sqrt(mean(a*a))\n",
        "    duration_am= mean(abs(a))\n",
        "    duration_summary= \"Offset Mean: %f, Std. Dev. from 0:%f\" %(duration_m, duration_s)\n",
        "    title =   \"Student \" + str(k)+ title_text2\n",
        "    duration_mean.append(duration_m)\n",
        "    duration_amean.append(duration_am)\n",
        "    duration_std.append(duration_s)\n",
        "\n",
        "    plt.title(title)\n",
        "    plt.figure(1, figsize=(9.5, 6))\n",
        "    plt.hist(a)\n",
        "\n",
        "    plt.show()\n",
        "    print(\" Grade = \", list0[k])\n",
        "    print(duration_summary)\n",
        "    studentStatistics = []\n",
        "    studentStatistics.append(str(k+1))\n",
        "    studentStatistics.append(round(listp[k],3))\n",
        "    studentStatistics.append(round(listr[k],3))\n",
        "    studentStatistics.append(round(listf[k],3))\n",
        "    print(\"F-measure = \", round(listf[k],3))\n",
        "    studentStatistics.append(round(onset_am,3))\n",
        "    studentStatistics.append(round(onset_m,3))\n",
        "    studentStatistics.append(round(onset_s,3))   \n",
        "    studentStatistics.append(round(duration_am,3))                   \n",
        "    studentStatistics.append(round(duration_m,3)) \n",
        "    studentStatistics.append(round(duration_s,3))   \n",
        "    studentStatistics.append(list0[k])\n",
        "\t  # write the data\n",
        "\t  #writer.writerow(studentStatistics)\n",
        "    studentStatisticsArray.append(studentStatistics)\n",
        "    \n",
        "  return(onset_mean, onset_std, duration_mean, duration_std,studentStatisticsArray,onset_amean, duration_amean)\n",
        "# Capture a table of onset and grade"
      ],
      "metadata": {
        "id": "bQeqI_ejzjQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(onset_stem_array[4])\n",
        "print(offset_stem_array[4])"
      ],
      "metadata": {
        "id": "gN35l6_mk7lc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hxf7p37yFg9x"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stem_index = 0 #int(input())\n",
        "print(edur_array,dur_array)\n",
        "sprecision_array = []\n",
        "srecall_array   = []\n",
        "sf_measure_value_array = []\n",
        "ofset_deviationsArray=[]"
      ],
      "metadata": {
        "id": "WWp9rX7rxLeJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 0.004505\n",
        "onsetEC, offsetEC, split_decision_func,_= myOnsetEnergyChecker(raw_audio,frameSize,hopSize, threshold)\n",
        "print(len(onsetEC))\n",
        "print(len(offsetEC))\n",
        "onsetEC2, offsetEC2,split_decision_func2,_= myOnsetEnergyChecker(raw_audio2,frameSize,hopSize, threshold)\n",
        "print(len(onsetEC2))\n",
        "print(len(offsetEC2))"
      ],
      "metadata": {
        "id": "qg3bXgTV7Hjm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(raw_audio)/44100/60)"
      ],
      "metadata": {
        "id": "Wsg2itGVC9-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "jJdmA4tr-nnd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mF9auqcZ7oww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "finals = [445100,292800,511700,286250,503860,331200,332550,375350,536300,538150,574300,581400,591000,569500,532800,578100]\n",
        "print(len(finals))\n"
      ],
      "metadata": {
        "id": "nr-kKcafBI-K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66097191-9582-4074-ce61-b479cef00797"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def write_stats(deviationsArray1,deviationsArray2,title_text1,title_text2,student_grades,sp,sr,sf,stem_index):\n",
        "\n",
        "  header = header2TF\n",
        "\n",
        "  fname =   'drive/MyDrive/Thesis/Experiments/' + DATA_PATH + dash + songList[stem_index] + dash + 'StudentStatistics_'+ songList[stem_index]  + '.csv'\n",
        "  testindex=0\n",
        "  with open(fname, 'w', encoding='UTF8') as f:\n",
        "     writer = csv.writer(f)\n",
        "     # write the header\n",
        "     writer.writerow(header)\n",
        "\n",
        "     studentStatistics = []\n",
        "     onset_X = []  # Martis mark\n",
        "     onset_amean = []\n",
        "     onset_mean = []\n",
        "     onset_std= []\n",
        "\n",
        "     duration_X = [] # Martis mark\n",
        "     duration_amean = []\n",
        "     duration_mean = []\n",
        "     duration_std= []\n",
        "     jin=0\n",
        "     for k in range(len(student_grades)):\n",
        "        print(\"************************************************************\", k)\n",
        "\n",
        "        studentStatistics.append(str(k+1))\n",
        "        student_stats1 = [] # onsets\n",
        "        student_stats2 = [] # durations\n",
        "\n",
        "        a = np.array(deviationsArray1[k])\n",
        "        print(len(a))\n",
        "        #print(a[0:11])\n",
        "        onset_m = mean(a)\n",
        "        onset_s=sqrt(mean(a*a))\n",
        "        onset_am= mean(abs(a))\n",
        "        onset_summary= \"Onset ABS  Mean: %f,Onset Mean: %f, Dev. from 0: %f\" %(onset_am,onset_m, onset_s)\n",
        "        #print(\"onset_summary: \",onset_summary)\n",
        "        title =   \"Student \" + str(k+1)+ title_text1\n",
        "\n",
        "        onset_X.append( student_grades[k][0])  # Martis mark\n",
        "        onset_mean.append(onset_m)\n",
        "        onset_amean.append(onset_am)\n",
        "        onset_std.append(onset_s)\n",
        "        if (len(deviationsArray2[k])==0):\n",
        "            a = np.array(deviationsArray2[k])\n",
        "            duration_m = 0\n",
        "            duration_s = 0\n",
        "            duration_am = 0\n",
        "        else:\n",
        "            a = np.array(deviationsArray2[k])\n",
        "            duration_m, duration_s = mean(a), sqrt(mean(a*a))\n",
        "            duration_am= mean(abs(a))\n",
        "        duration_summary= \"Offset Mean: %f, Dev. from 0: %f\" %(duration_m, duration_s)\n",
        "        title =   \"Student \" + str(k+1)+ title_text2\n",
        "        #print(\"duration_summary: \",duration_summary)\n",
        "\n",
        "        duration_mean.append(duration_m)\n",
        "        duration_amean.append(duration_am)\n",
        "        duration_std.append(duration_s)\n",
        "\n",
        "        studentStatistics = []\n",
        "        studentStatistics.append(str(k))\n",
        "        studentStatistics.append(round(sp[k],3))\n",
        "        studentStatistics.append(round(sr[k],3))\n",
        "        studentStatistics.append(round(sf[k],3))\n",
        "        studentStatistics.append(round(onset_am,3))\n",
        "        studentStatistics.append(round(onset_m,3))\n",
        "        studentStatistics.append(round(onset_s,3))   \n",
        "        studentStatistics.append(round(duration_am,3))                   \n",
        "        studentStatistics.append(round(duration_m,3)) \n",
        "        studentStatistics.append(round(duration_s,3))   \n",
        "        studentStatistics.append(student_grades[k]) # Overall Grade\n",
        "        # write the data\n",
        "        writer.writerow(studentStatistics)\n",
        "\n",
        "  return(onset_X, onset_mean, onset_std, duration_X, duration_mean, duration_std)"
      ],
      "metadata": {
        "id": "CGbbqycKDYB9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(onset_list)"
      ],
      "metadata": {
        "id": "EWiX9jk_Cv43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7GPuro1-Ar_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We get the PRF of the GT STEM\n",
        "if  len(onset_list) == 0 or len(offset_list) == 0:\n",
        "    print(\"ERROR IN READING THE ONSET AND OFFSET LISTS\")\n",
        "else:\n",
        "    precision, recall, f_measure_value = evaluate_accuracy(onset_list, new_onset_stem_array, matching_window_size)\n",
        "\n",
        "print(songList[stem_index],\"STEM  precision, recall, f_measure_value\", precision, recall, f_measure_value)\n",
        "\n",
        "# APPEND THE \"STUDENT 0\" OR STEM TO THE \"S ARRAYS\".. Remember array position 0 for Student 0 represent the STEM\n",
        "sprecision_array.append(precision)\n",
        "srecall_array.append(recall)\n",
        "sf_measure_value_array.append(f_measure_value)\n",
        "\n",
        "# WE CALCULATE THE DEVIATIONS OF THE STEM !!!! NOT NEEEDED STEM IS 100%\n",
        "onset_deviations, offset_deviations, missing_onset_notes = match_rhythm(df, new_onset_stem_array, new_offset_stem_array,matching_window_size)\n",
        "sonset_deviationsArray.append(onset_deviations)\n",
        "soffset_deviationsArray.append(onset_deviations)\n",
        "\n",
        "########################## WRITE THE DEVIATIONS FOR STUDENT 0 OR STEM \n",
        "# Save the deviations in a file for the stem\n",
        "\n",
        "theFilePath = 'drive/MyDrive/Thesis/Experiments/'+DATA_PATH + dash + songList[stem_index] + dash + songList[stem_index] + '_devs_student0'+'.csv'\n",
        "f1 = open(theFilePath, \"w\")\n",
        "print(theFilePath)\n",
        "f1.write(\"onset dev\")\n",
        "f1.write(\",\")\n",
        "f1.write(\"offset dev\")\n",
        "f1.write(\"\\n\")\n",
        "index=0\n",
        "while index < len(onset_deviations):\n",
        "    f1.write(str(onset_deviations[index]))\n",
        "    f1.write(\",\")\n",
        "    if index < len(offset_deviations):\n",
        "        f1.write(str(offset_deviations[index]))\n",
        "    else:\n",
        "        f1.write(str(0.0))   \n",
        "    f1.write(\"\\n\")\n",
        "    index+=1\n",
        "f1.close\n",
        "\n",
        "########################## STUDENT 1..N\n",
        "\n",
        "student_index= 0\n",
        "numOfStudents = 16 #getNumberOfStudents (stem_index)\n",
        "f_array=[]\n",
        "while student_index < numOfStudents:\n",
        "   \n",
        "    studentAudioFilename  = 'drive/MyDrive/Thesis/Experiments/'+studentFilenames[student_index]\n",
        "    snew_onset_stem_array, snew_offset_stem_array,sed = call_sop(studentAudioFilename,str(0))\n",
        "    sprecision, srecall, sf_measure_value = evaluate_accuracy(stem_list, snew_onset_stem_array, matching_window_size)\n",
        "    sprecision_array.append(sprecision)\n",
        "    #print(student_index+1 ,\" IEC Student precision, recall, f_measure_value\", sprecision, srecall, sf_measure_value)\n",
        "\n",
        "    #dprecision, drecall, df_measure_value = evaluate_accuracy(onset_list, sed, matching_window_size)\n",
        "\n",
        "\n",
        "    #print(student_index+1 ,\" Duration Energy Fidelity \", dur_Accuracy)\n",
        "    sonset_deviations,soffset_deviations, smissing_onset_notes = match_rhythm(df, snew_onset_stem_array,snew_offset_stem_array,matching_window_size)\n",
        "\n",
        "    # Append Student onset/offsets\n",
        "    f_array.append(sf_measure_value)\n",
        "    srecall_array.append(srecall)\n",
        "    sf_measure_value_array.append(sf_measure_value)\n",
        "    sonset_deviationsArray.append(sonset_deviations)\n",
        "    soffset_deviationsArray.append(soffset_deviations)\n",
        "\n",
        "    theFilePath = 'drive/MyDrive/Thesis/Experiments/'+DATA_PATH+dash+songList[stem_index]+dash+songList[stem_index]+ '_devs_student' +str(student_index+1)+'.csv'\n",
        "\n",
        "    ########################## WRITE THE DEVIATIONS FOR STUDENTS 1...NameError\n",
        "    f3 = open(theFilePath, \"w\")\n",
        "    f3.write(\"onset dev\")\n",
        "    f3.write(\",\")\n",
        "    f3.write(\"offset dev\")\n",
        "    f3.write(\"\\n\")\n",
        "    dev_index=0\n",
        "    while dev_index < len(sonset_deviations):\n",
        "        f3.write(str(sonset_deviations[dev_index]))\n",
        "        f3.write(\",\")\n",
        "        if dev_index < len(soffset_deviations):\n",
        "            f3.write(str(soffset_deviations[dev_index]))\n",
        "        else:\n",
        "            f3.write(str(0.0))   \n",
        "        f3.write(\"\\n\")\n",
        "        dev_index+=1\n",
        "        f3.close\n",
        "    student_index+=1\n",
        "\n",
        "\n",
        "\n",
        "########################## WRITE THE STATISICS FOR STUDENT0, 1- N\n",
        "\n",
        "\n",
        "if (len(sonset_deviationsArray)==0) or (len(soffset_deviationsArray)==0):\n",
        "    print(\"Warning: ZERO DEVIATIONS\")\n",
        "\n",
        "if (len(sonset_deviationsArray[0])==0) or (len(soffset_deviationsArray[0])==0):\n",
        "    print(\"Warning: ZERO DEVIATIONS at STEM\")\n",
        "\n",
        "\n",
        "if (len(sprecision_array) == 0) or (len(srecall_array) == 0):\n",
        "    print(\"Warning: ZERO PRFS\")\n"
      ],
      "metadata": {
        "id": "j0wogOX0mBfH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(finals[:13]))\n",
        "print(len(f_array))"
      ],
      "metadata": {
        "id": "7WjmbHs1O7hr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "\n",
        "import plotly.express as px\n",
        "\n",
        "x1=f_array\n",
        "y1=finals\n",
        "x2=x1[0:9]\n",
        "y2=y1[0:9]\n",
        "x4=x1[12:16]\n",
        "y4=y1[12:16]\n",
        "x5=x2+x4\n",
        "y5=y2+y4 \n",
        "fig = px.scatter(x=x5, y=y5)\n",
        "fig.show()\n",
        "fig = px.scatter(x=x2, y=y2)\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "c6FRygsLOw2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print((snew_onset_stem_array))\n",
        "print((onset_list))"
      ],
      "metadata": {
        "id": "PfwmORzqIkyB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sonset_deviationsArray)\n",
        "print(len(sonset_deviationsArray))"
      ],
      "metadata": {
        "id": "FxniQsYwF1W3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#write_stats(sonset_deviationsArray,soffset_deviationsArray,\" onsets\", \" offset\",the_student_grades,sprecision_array,srecall_array,sf_measure_value_array,stem_index)\n"
      ],
      "metadata": {
        "id": "JXG3xKN3FzA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "\n",
        "import plotly.express as px\n",
        "\n",
        "x1=f_array\n",
        "y1=finals\n",
        "x2=x1[0:9]\n",
        "y2=y1[0:9]\n",
        "x4=x1[12:16]\n",
        "y4=y1[12:16]\n",
        "x5=x2+x4\n",
        "y5=y2+y4 \n",
        "fig = px.scatter(x=x5, y=y5)\n",
        "fig.show()\n",
        "fig = px.scatter(x=x2, y=y2)\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "syE9tVLXiuaX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.graph_objects as go\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(dict(\n",
        "    date=[\"1995-01-10\", \"2000-01-10\", \"2005-01-10\", \"2010-01-10\", \"2015-01-10\", \"2020-01-10\"],\n",
        "    value=[1,2,3,4,5,6]\n",
        "))\n",
        "\n",
        "fig = go.Figure()\n",
        "\n",
        "\n",
        "fig.add_trace(go.Scatter(\n",
        "    name=\"Middle-aligned\",\n",
        "    mode=\"markers\", x=df[\"date\"], y=df[\"value\"],\n",
        "    xperiod=\"M1\",\n",
        "    xperiodalignment=\"middle\"\n",
        "))\n",
        "\n",
        "fig.add_trace(go.Bar(\n",
        "    name=\"Middle-aligned\",\n",
        "    x=df[\"date\"], y=df[\"value\"],\n",
        "    xperiod=\"M1\",\n",
        "    xperiodalignment=\"middle\"\n",
        "))\n",
        "fig.update_xaxes(showgrid=True, ticklabelmode=\"period\")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "gZEMe7lO5Ili"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}