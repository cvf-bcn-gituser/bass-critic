# -*- coding: utf-8 -*-
"""OnsetOffsetColmAlgorithms_Dataset_Frauenhofer.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12CL_4_UDCkJgKSth5IbAsIVbylotOxjn

### OFFSET AND ONSET DETECTION FOR ABBESSER DATASET- Colm Forkin
Here we have a Frame-based analysis, low-level feature estimation: energy and maxima based approach to detecting Onsets and Offsets.
Based on considering energy, both onsets and offsets  are checked  in a monotonically increasing approach (frame by frame)  to the signal, that ensures that the offset detection is dependent on the onset detection, so no anomalies can occur.


The core function in this notebook is called myOnsetEnergyChecker().
This function returns "start_indexes, stop_indexes".
(apologies for using the word "index" here. This suggest it is an integer value.
INDEXES REPRESENT FLOAT POINT VALUES INSTANCES IN SECONDS

There is additionaloutput parameters from the  
function  myOnsetEnergyChecker()  that allows consideration of other onset detection functions (e.g. onsets_hfc) and other information (split_decision_func) but for now these returned values are not considered in the Histogram Plots.

There are 17  audio files considered from Abessers Dataset

The Histogram plots only considers the 002.wav (and corresponding 002.xml ground truth)

The full set of audio consider in the Data loader are area aligned with a set of ground truth values for both onset and offset. Ther are paired up as follows;
"""

!pip3 install essentia

!pip3 install madmom

!pip3 install mir_eval

"""The section below is all path dependent"""

from google.colab import drive
drive.mount("/content/drive", force_remount=True)
root = 'drive/MyDrive/Bass/'
import pandas as pd
import sys
sys.path.append(root)

import madmom

# TODO 1 optimise imports
from essentia.standard import *
from essentia import Pool, array
import essentia.standard as es
import matplotlib.pyplot as plt
import numpy as np
import IPython.display as ipd
import pandas as pd
import os

import IPython
import pickle
from pickle import load
from scipy.signal import find_peaks
import ipywidgets as widgets
from scipy import signal
from lxml import etree

import plotly.express as px

import mir_eval
from mir_eval import *

!ls drive/MyDrive/Bass

# 1. Preparing the Dataset (wav and annotations)
audio_files1 = ['drive/MyDrive/Bass/00'+ str(i) + '.wav' for i in range(10)]

audio_files1.pop(0)
audio_files2 = ['drive/MyDrive/Bass/01'+ str(i) + '.wav' for i in range(8)]
audio_files=audio_files1+audio_files2
# 1. Preparing the Dataset (wav and annotations)
annotation_files1 = ['drive/MyDrive/Bass/00'+ str(i) + '.xml' for i in range(10)]
annotation_files1.pop(0)
annotation_files2 = ['drive/MyDrive/Bass/01'+ str(i) + '.xml' for i in range(8)]
annotation_files=annotation_files1+annotation_files2

assert(len(audio_files) == len(annotation_files))

ground_t_offsets_array = []
ground_t_onsets_array = []
ground_t_durations_array = []

# To Colm: just always use absolute time in the annotations.
# scaled_factor=1 #or fs depending on whether the graph uses time of samples

def extract_onsets_offsets_from_xml(xml_filename):
    with open(xml_filename, "rb") as f:
        tree = etree.parse(f)
    ground_t_offsets= []
    ground_t_onsets= []
    for x in tree.getroot().xpath("//offsetSec"):
        ground_t_offsets.append(float(x.text))
    for x in tree.getroot().xpath("//onsetSec"):
        ground_t_onsets.append(float(x.text))
    return ground_t_onsets, ground_t_offsets

for xml_file in annotation_files:
    print(xml_file)
    ground_t_onsets, ground_t_offsets = extract_onsets_offsets_from_xml(xml_file)  
    ground_t_durations = array(ground_t_offsets)-array(ground_t_onsets)
    ground_t_offsets_array.append(array(ground_t_offsets))
    ground_t_onsets_array.append(array(ground_t_onsets))
    ground_t_durations_array.append(array(ground_t_durations))

# 2. Load the audio for the Dataset
raw_audio = []
fs = 44100
for audio_file in audio_files:
    raw = MonoLoader(filename = audio_file, sampleRate = fs)()
    raw = raw / np.max(np.abs(raw))
    raw_audio.append(raw)

def match_duration(gt_onsets, onsets, gt_offsets, offsets, matching_window_size):
    """
    Finds best matching pairs so
       - distance between elements is no greater than matching_window_size
       - sum of all distances is is minimized
       - also returns the fidelity ( conformance to 100% hit notes)
    """
    # Not sure yet what to do with these statistics.
    # Late onset metrics
    lods=0 # duration short
    lodl=0 # duration long               
    lodb=0 # duration bang on    
    # Early  onset metrics         
    eods=0  # duration short
    eodl=0  # duration long
    eodb=0  # duration bang on
    # "Bang on" onset metrics
    bods=0  # duration short
    bodl=0  # duration long
    bodb=0  # duration bang on
    duration_violation = 0
    onset_early=0
    onset_late=0
    onset_bangon=0
    result = []
    missing_onset_notes= 0
    onset_deviation_array = []
    duration_deviation_array = []

    m = scipy.spatial.distance_matrix([[x] for x in gt_onsets], [[x] for x in onsets])
    # don't consider events which are out of matching window size
    big_distance = 10 ** 6
    m[m > matching_window_size] = big_distance

    n = scipy.spatial.distance_matrix([[x] for x in gt_offsets], [[x] for x in offsets])
    # don't consider events which are out of matching window size
    big_distance = 10 ** 6
    n[n > matching_window_size] = big_distance

    row_ons, col_ons = scipy.optimize.linear_sum_assignment(m)
    row_offs, col_offs = scipy.optimize.linear_sum_assignment(n)

    for (xn, yn, xf, yf) in zip(row_ons, col_ons,row_offs, col_offs):
        # Lets calculate the ground truth duration from onset/offset
        gt_duration = gt_offsets[xf]-gt_onsets[xn]
        #print("gt_duration",gt_duration)
        if abs(gt_onsets[xn] - onsets[yn]) <= matching_window_size:
            # We are within margin
            # This is initialization of the duration deviation
            duration_deviation = 0
            if (onsets[yn]> gt_onsets[xn]): # then it is a late onset wrt GT
                real_duration  = offsets[yf]- onsets[yn]
                if (real_duration<gt_duration):
                # late onset,  duration is short
                   lods+=1
                   duration_deviation= gt_duration-real_duration
                   # Since its shiort we call it negative
                   duration_deviation = -duration_deviation
                elif (real_duration>gt_duration):
                # late onset,  duration is long
                   lodl+=1        
                   duration_deviation = real_duration-gt_duration       
                elif (real_duration==gt_duration):
                # late onset,  duration bang on
                   lodb+=1 
                   duration_deviation= 0
                # Calculate the deviations         
                onset_deviation = onsets[yn] - gt_onsets[xn]
                onset_late+=1
            elif (onsets[yn]< gt_onsets[xn]): # then it is a early onset
                # Check the real duratation against the GT duration in this early case
                real_duration  = offsets[yf] - onsets[yn]
                # This is initialization of the duration deviation
                duration_deviation = 0
                if (real_duration<gt_duration):
                # early onset,  duration is short
                   eods+=1  
                   duration_deviation= gt_duration-real_duration
                   # Since its shiort we call it negative
                   duration_deviation = -duration_deviation
                elif (real_duration>gt_duration):
                   # early onset,  duration is long
                   eodl+=1  
                   duration_deviation = real_duration-gt_duration   
                elif (real_duration==gt_duration):
                   # early onset,  duration bang on 
                   eodb+=1  
                   duration_deviation = 0
                else:
                   duration_violation+=1
                #Calculate the deviations         
                temp =  gt_onsets[xn]-onsets[yn] 
                onset_deviation = -temp
                onset_early+=1
            elif (onsets[yn]== gt_onsets[xn]): # default else onset bang on 
                # Check the real duratation against the GT duration in this early case
                real_duration  = offsets[yf] - onsets[yn]
                duration_deviation = 0
                if (real_duration<gt_duration):
                # bang on onset,  duration is short
                   bods+=1  
                   duration_deviation= gt_duration-real_duration
                   # Since its shiort we call it negative
                   duration_deviation = -duration_deviation
                elif (real_duration>gt_duration):
                # bang on onset,  duration is long
                   bodl+=1  
                   duration_deviation = real_duration-gt_duration 
                elif (real_duration==gt_duration):
                # bang on onset,  duration bang on 
                   bodb+=1  
                   duration_deviation = 0
                onset_deviation=0 
                onset_bangon+=1   
            onset_deviation_array.append(onset_deviation) 
            if (abs(duration_deviation)<1): # remove outliers
              duration_deviation_array.append(duration_deviation)
            else: 
              duration_violation+=1
        else:
            missing_onset_notes+=1
    print("lods,lodl,lodb, eods,eodl,eodb, bods,bodl,bodb,duration_violation")
    print(lods,lodl,lodb, eods,eodl,eodb, bods,bodl,bodb,duration_violation)
    return onset_deviation_array,duration_deviation_array,missing_onset_notes

# 3. Defining accuracy metrics.
import scipy

def match_events(gt_onsets, onsets, matching_window_size):
    """
    Finds best matching pairs so
       - distance between elements is no greater than matching_window_size
       - sum of all distances is is minimized
       - also returns the fidelity ( conformance to 100% hit notes)

    """
    # In case of performance issues for big piecs,
    # we could try to use simpler/faster local algorithm.
    m = scipy.spatial.distance_matrix([[x] for x in gt_onsets], [[x] for x in onsets])
    # don't consider events which are out of matching window size
    big_distance = 10 ** 6
    m[m > matching_window_size] = big_distance

    row_ind, col_ind = scipy.optimize.linear_sum_assignment(m)
    result = []
    missing_notes= 0
    deviated_notes = []
    for (x, y) in zip(row_ind, col_ind):
        if abs(gt_onsets[x] - onsets[y]) <= matching_window_size:
            result.append((x, y))
            # We are within marging lets get mlroe details on difference
            if (onsets[y]> gt_onsets[x]): # then it is late
              deviation = onsets[y] - gt_onsets[x]
            elif (onsets[y]< gt_onsets[x]): # then it is early
              diff =  gt_onsets[x] - onsets[y]
              deviation = -diff
            elif (onsets[y]== gt_onsets[x]): # then it is bang on
              deviation=0    
            deviated_notes.append(deviation)
        else:
            missing_notes+=1
     # How many missing as % of total?
    total_notes= len(onsets)
    delta_missing_notes= total_notes-missing_notes
    fidelity = round( 100.0*(delta_missing_notes/total_notes),4)     
    return result,fidelity,deviated_notes

def f_measure(precision, recall):
    if precision == 0 and recall == 0:
        return 0.0
    return 2.0 * precision*recall / (precision + recall)




def evaluate_accuracy(gt_onsets, onsets, matching_window_size):
    matching,_,_ = match_events(
        gt_onsets,
        onsets,
        matching_window_size)
    precision = float(len(matching)) / len(onsets)
    recall = float(len(matching)) / len(gt_onsets)
    f_measure_value = f_measure(precision, recall)
    return precision, recall, f_measure_value

#Setting the parameters try *2 also
windowSize = 1024*2
hopSize = 512*2
startIndexes = np.arange(0, raw_audio[0].size - windowSize, hopSize, dtype = int)#frame/window start indexes
numWindows = startIndexes.size

"""The energy of a discrete time signal can be computed as:
\begin{equation}
energy = \sum_{n = 0}^{N-1} |x[n]|^2
\end{equation}
where x[n] refers to the discrete time signal sample at index n
"""

# Onset detection using Spectral Onset Processor blending ideas from Ramon
# myOnsetEnergyChecker
# Returns 
def myOnsetEnergyChecker(x,theFrameSize,theHopSize,thresh):
    NRG = [];
    #Main windowing and feature extraction loop
    #for frame in es.FrameGenerator(x, frameSize = windowSize, hopSize = hopSize, startFromZero = True):
    for frame in FrameGenerator(x, frameSize = theFrameSize, hopSize = theHopSize):
        NRG.append(es.Energy()(frame))
    NRG = np.array(NRG)
    NRG = NRG / np.max(NRG)
    #Applying energy threshold to decide wave split boundaries
    split_decision_func = np.zeros_like(NRG)
    split_decision_func[NRG > thresh] = 1 # was 0.005
    #Setting segment boundaries
    #Inserting a zero at the beginning since we will decide the transitions using a diff function
    split_decision_func = np.insert(split_decision_func, 0, 0)
    diff_split_decision = np.diff(split_decision_func)
    #Start indexes: transition from 0 to 1
    start_indexes = np.nonzero(diff_split_decision > 0)[0] * hopSize/fs
    #Stop indexes: transition from 1 to 0
    stop_indexes = np.nonzero(diff_split_decision < 0)[0] * hopSize/fs
    # TODO we have an issue here 
    #duration  = stop_indexes-start_indexes[1:len(start_indexes-1)]

    start_indexes=start_indexes[0:len(start_indexes)-1]
    return (start_indexes, stop_indexes)

frameSize = 2048
hopSize = 1024

from statistics import mean

myOnsetEnergyCheckerThreshold= 0.05 
matching_window_size = 0.05 # MIREX reference
p= []
r= []
f = []
OnsetCalculateOffsetOnset = []
onsetIndexArray =  []
offsetIndexArray =  []
durationIndexArray =  []
onset_deviationsArray  =  []
duration_deviationsArray  =  []
missing_onset_notesArray  =  []
for i in range(len(raw_audio)):
    onsetIndex, offsetIndex = myOnsetEnergyChecker(raw_audio[i],frameSize,hopSize,myOnsetEnergyCheckerThreshold) 
    onsetIndexArray.append(onsetIndex)
    offsetIndexArray.append(offsetIndex)
    
    # After break , calculate 
    precision, recal, f_measure_value=evaluate_accuracy(ground_t_onsets_array[i], onsetIndex, matching_window_size)
    print("WAV file number", i+1 ," precision, recall, f_measure_value",precision, recal, f_measure_value)
    print("\n")
    p.append(precision)
    r.append(recal)
    f.append(f_measure_value)

    p1=ground_t_onsets_array[i]
    p2=onsetIndex
    p3=ground_t_offsets_array[i] 
    p4=offsetIndex
    p5=matching_window_size
    onset_deviations,duration_deviations,missing_onset_notes =   match_duration(p1,p2,p3,p4,p5)
    print("WAV file number",i+1 ," missing_onset_notes",missing_onset_notes)

    onset_deviationsArray.append(onset_deviations)
    duration_deviationsArray.append(duration_deviations)
    missing_onset_notesArray.append(missing_onset_notes)


print("\n lo= late onset, eo = early onset, dl= duration long, ds = duration short, bo= bang on \n")

#################
plt.plot(np.arange(raw_audio[1].size)/float(fs), raw_audio[1],'b')
plt.axis([0,raw_audio[1].size/float(fs),min(raw_audio[1]),max(raw_audio[1])])
for i in onsetIndexArray[1]:
    plt.axvline(x=i, color='red')
plt.title("onsetIndexArray")
plt.show()
########################################################################################

plt.plot(np.arange(raw_audio[1].size)/float(fs), raw_audio[1],'b')
plt.axis([0,raw_audio[1].size/float(fs),min(raw_audio[1]),max(raw_audio[1])])
for i in ground_t_onsets_array[1]:
    plt.axvline(x=i, color='green')
plt.title("Ground Truth")
plt.show()

# offsetColmArray.append(onsetFirst)   
# offsetIndexArray.append(offsetIndex) 
plt.plot(np.arange(raw_audio[1].size)/float(fs), raw_audio[1],'b')
plt.axis([0,raw_audio[1].size/float(fs),min(raw_audio[1]),max(raw_audio[1])])
for i in offsetIndexArray[1]:
    plt.axvline(x=i, color='yellow')
plt.title("NRG (INDEX) based offset Algorithm to estimate")
plt.show()
########################################################################################


golden_onsets_0 = array(ground_t_offsets_array[1])

plt.plot(np.arange(raw_audio[1].size)/float(fs), raw_audio[1],'b')
plt.axis([0,raw_audio[1].size/float(fs),min(raw_audio[1]),max(raw_audio[1])])
for i in ground_t_offsets_array[1]:
    plt.axvline(x=i, color='green')
plt.title("Ground Truth Offset ANNOTATED")
plt.show()
########################################################################################

import pandas as pd
print(len(duration_deviationsArray))

index=0
while index <17:
  strname= 'Colm Durations'+str(index+1)
  data_timing_duration= { strname :duration_deviationsArray[index]}
  df = pd.DataFrame(data_timing_duration,columns=[strname])
  fig = px.histogram(df, x=strname)
  fig.show()
  index+=1

index=0
while index <17:
  strname= 'Colm Onsets '+str(index+1)
  data_timing_onsets= { strname :onset_deviationsArray[index]}
  df = pd.DataFrame(data_timing_onsets,columns=[strname])
  fig = px.histogram(df, x=strname)
  fig.show()
  index+=1

index=0
while index <9:
  fname= "drive/MyDrive/Bass/"+"00"+str(index+1)+"onset_dev.csv"
  print(fname)
  f = open(fname, 'r+')
  content_array = []
  for line in f:
    content_array.append(line)
  strname= 'Abesser onsets '+str(index+1)
  data_timing_onset= { strname :content_array}
  df = pd.DataFrame(data_timing_onset,columns=[strname])
  fig = px.histogram(df, x=strname)
  fig.show()
  f.close()
  index+=1
while index < 16:
  fname= "drive/MyDrive/Bass/"+"0"+str(index+1)+"onset_dev.csv"
  print(fname)
  f = open(fname, 'r+')
  content_array = []
  for line in f:
    content_array.append(line)
  strname= 'Abesser onsets '+str(index+1)
  data_timing_onset= { strname :content_array}
  df = pd.DataFrame(data_timing_onset,columns=[strname])
  fig = px.histogram(df, x=strname)
  fig.show()
  f.close()
  index+=1

index=0
while index <9:
  fname= "drive/MyDrive/Bass/"+"00"+str(index+1)+"duration_dev.csv"
  print(fname)
  f = open(fname, 'r+')
  content_array = []
  for line in f:
    content_array.append(line)
  strname= 'Abesser onsets '+str(index+1)
  data_timing_onset= { strname :content_array}
  df = pd.DataFrame(data_timing_onset,columns=[strname])
  fig = px.histogram(df, x=strname)
  fig.show()
  f.close()
  index+=1
while index < 16:
  fname= "drive/MyDrive/Bass/"+"0"+str(index+1)+"duration_dev.csv"
  print(fname)
  f = open(fname, 'r+')
  content_array = []
  for line in f:
    content_array.append(line)
  strname= 'Abesser duration '+str(index+1)
  data_timing_duration= { strname :content_array}
  df = pd.DataFrame(data_timing_duration,columns=[strname])
  fig = px.histogram(df, x=strname)
  fig.show()
  f.close()
  index+=1