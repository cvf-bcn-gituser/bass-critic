# -*- coding: utf-8 -*-
"""EnergyChecker_vs_BassUNet_IDMT_Dataset.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12CL_4_UDCkJgKSth5IbAsIVbylotOxjn

### Onset/Duration Measurement: Comparisons of Deviations (using Histograms)
## EnergyChecker vs Abesser Unet
This notebook  compare two algorithsm for measuring duration and onset times

The first approach which I will call "EnergyChecker" approach ( in reality it is a a hybird of techniques based on Ramons methods)
Here we have a Frame-based analysis, low-level feature estimation: energy and maxima based approach to detecting Onsets and Offsets. Based on considering energy, both onsets and offsets  are checked  in a monotonically increasing approach (frame by frame)  to the signal, that ensures that the offset detection is dependent on the onset detection, so no anomalies can occur.

The core function in this approach is called myOnsetEnergyChecker().
This function returns "start_times, start_times".

There is additionaloutput parameters from the  function  myOnsetEnergyChecker()  that allows consideration of other onset detection functions (e.g. onsets_hfc) and other information (split_decision_func) but for now these returned values are not considered in the Histogram Plots.

There are 17 audio files considered from IDMT-SMT-BASS-SINGLE-TRACKS Dataset.

Teh second approach is base on Abessers BassUnet: Algorithm for bass transcription (joint frame-level pitch and voicing estimation) using U-Net Fully Convolutional Networks. This program was run in a  a different anocada environment. The results have been exported to a set of onset and duration deviation files
using the same IDMT dataset:

001onset_dev.csh
002onset_dev.csh
.
.
016onset_dev.csh

001duration_dev.csh
002duration_dev.csh
.
.
016duration_dev.csh

The deviation files are imported here for histogram plots.
(N.B the plots for 017.way  in Abessers Unet method are missing).

## Conclusions
There are weakness in how the duration is claculated.
This has been highlighted with the test variable "duations_vioaltions". It should more or less be the same as the number of missing offsets.
Perhaps ther is a better way to perfrom the matching of durations and onsets and a a suggestion is to look at https://github.com/jakobabesser/pymus/blob/master/README.rst to see how onset and duation are extracted and measured in pairs.
"""

!pip3 install essentia

Th!pip3 install madmom

!pip3 install mir_eval

"""The section below is all path dependent"""

from google.colab import drive
drive.mount("/content/drive", force_remount=True)
root = 'drive/MyDrive/Bass/'
import pandas as pd
import sys
sys.path.append(root)

import madmom

from essentia.standard import *
from essentia import Pool, array
import essentia.standard as es
import matplotlib.pyplot as plt
import numpy as np
import IPython.display as ipd
import pandas as pd
import os

import IPython
import pickle
from pickle import load
from scipy.signal import find_peaks
import ipywidgets as widgets
from scipy import signal
from lxml import etree

import plotly.express as px

import mir_eval
from mir_eval import *

# 1. Preparing the Dataset (wav and annotations)
audio_files1 = ['drive/MyDrive/Bass/00'+ str(i) + '.wav' for i in range(10)]

audio_files1.pop(0)
audio_files2 = ['drive/MyDrive/Bass/01'+ str(i) + '.wav' for i in range(8)]
audio_files=audio_files1+audio_files2
# 1. Preparing the Dataset (wav and annotations)
annotation_files1 = ['drive/MyDrive/Bass/00'+ str(i) + '.xml' for i in range(10)]
annotation_files1.pop(0)
annotation_files2 = ['drive/MyDrive/Bass/01'+ str(i) + '.xml' for i in range(8)]
annotation_files=annotation_files1+annotation_files2

assert(len(audio_files) == len(annotation_files))
ground_t_offsets_array = []
ground_t_onsets_array = []
ground_t_durations_array = []

# To Colm: just always use absolute time in the annotations.
# scaled_factor=1 #or fs depending on whether the graph uses time of samples

def extract_onsets_offsets_from_xml(xml_filename):
    with open(xml_filename, "rb") as f:
        tree = etree.parse(f)
    ground_t_offsets= []
    ground_t_onsets= []
    for x in tree.getroot().xpath("//offsetSec"):
        ground_t_offsets.append(float(x.text))
    for x in tree.getroot().xpath("//onsetSec"):
        ground_t_onsets.append(float(x.text))
    return ground_t_onsets, ground_t_offsets

for xml_file in annotation_files:
    print(xml_file)
    ground_t_onsets, ground_t_offsets = extract_onsets_offsets_from_xml(xml_file)  
    ground_t_durations = array(ground_t_offsets)-array(ground_t_onsets)
    ground_t_offsets_array.append(array(ground_t_offsets))
    ground_t_onsets_array.append(array(ground_t_onsets))
    ground_t_durations_array.append(array(ground_t_durations))

# 2. Load the audio for the Dataset
raw_audio = []
fs = 44100
for audio_file in audio_files:
    raw = MonoLoader(filename = audio_file, sampleRate = fs)()
    raw = raw / np.max(np.abs(raw))
    raw_audio.append(raw)

def match_duration(gt_onsets, onsets, gt_offsets, offsets, matching_window_size):
    """
    Finds best matching pairs so
       - distance between elements is no greater than matching_window_size
       - sum of all distances is is minimized
       - also returns the fidelity ( conformance to 100% hit notes)
    """
    # Not sure yet what to do with these statistics.
    # Late onset metrics
    lods=0 # duration short
    lodl=0 # duration long               
    lodb=0 # duration bang on    
    # Early  onset metrics         
    eods=0  # duration short
    eodl=0  # duration long
    eodb=0  # duration bang on
    # "Bang on" onset metrics
    bods=0  # duration short
    bodl=0  # duration long
    bodb=0  # duration bang on
    duration_violation = 0 # Counter for amount of times the duration window is violated
    duration_limit = 1 # We make the duration window max. size generous to begin with.
    onset_early=0
    onset_late=0
    onset_bangon=0
    result = []
    missing_onset_notes= 0
    onset_deviation_array = []
    duration_deviation_array = []

    m = scipy.spatial.distance_matrix([[x] for x in gt_onsets], [[x] for x in onsets])
    # don't consider events which are out of matching window size
    big_distance = 10 ** 6
    m[m > matching_window_size] = big_distance

    n = scipy.spatial.distance_matrix([[x] for x in gt_offsets], [[x] for x in offsets])
    # don't consider events which are out of matching window size
    big_distance = 10 ** 6
    n[n > matching_window_size] = big_distance

    row_ons, col_ons = scipy.optimize.linear_sum_assignment(m)
    row_offs, col_offs = scipy.optimize.linear_sum_assignment(n)

    for (xn, yn, xf, yf) in zip(row_ons, col_ons,row_offs, col_offs):
        # Lets calculate the ground truth duration from onset/offset
        gt_duration = gt_offsets[xf]-gt_onsets[xn]
        #print("gt_duration",gt_duration)
        if abs(gt_onsets[xn] - onsets[yn]) <= matching_window_size:
            # We are within margin
            # This is initialization of the duration deviation
            duration_deviation = 0
            if (onsets[yn]> gt_onsets[xn]): # then it is a late onset wrt GT
                real_duration  = offsets[yf]- onsets[yn]
                if (real_duration<gt_duration):
                # late onset,  duration is short
                   lods+=1
                   duration_deviation= gt_duration-real_duration
                   # Since its shiort we call it negative
                   duration_deviation = -duration_deviation
                elif (real_duration>gt_duration):
                # late onset,  duration is long
                   lodl+=1        
                   duration_deviation = real_duration-gt_duration       
                elif (real_duration==gt_duration):
                # late onset,  duration bang on
                   lodb+=1 
                   duration_deviation= 0
                # Calculate the deviations         
                onset_deviation = onsets[yn] - gt_onsets[xn]
                onset_late+=1
            elif (onsets[yn]< gt_onsets[xn]): # then it is a early onset
                # Check the real duratation against the GT duration in this early case
                real_duration  = offsets[yf] - onsets[yn]
                # This is initialization of the duration deviation
                duration_deviation = 0
                if (real_duration<gt_duration):
                # early onset,  duration is short
                   eods+=1  
                   duration_deviation= gt_duration-real_duration
                   # Since its shiort we call it negative
                   duration_deviation = -duration_deviation
                elif (real_duration>gt_duration):
                   # early onset,  duration is long
                   eodl+=1  
                   duration_deviation = real_duration-gt_duration   
                elif (real_duration==gt_duration):
                   # early onset,  duration bang on 
                   eodb+=1  
                   duration_deviation = 0
                else:
                   duration_violation+=1
                #Calculate the deviations         
                temp =  gt_onsets[xn]-onsets[yn] 
                onset_deviation = -temp
                onset_early+=1
            elif (onsets[yn]== gt_onsets[xn]): # default else onset bang on 
                # Check the real duratation against the GT duration in this early case
                real_duration  = offsets[yf] - onsets[yn]
                duration_deviation = 0
                if (real_duration<gt_duration):
                # bang on onset,  duration is short
                   bods+=1  
                   duration_deviation= gt_duration-real_duration
                   # Since its shiort we call it negative
                   duration_deviation = -duration_deviation
                elif (real_duration>gt_duration):
                # bang on onset,  duration is long
                   bodl+=1  
                   duration_deviation = real_duration-gt_duration 
                elif (real_duration==gt_duration):
                # bang on onset,  duration bang on 
                   bodb+=1  
                   duration_deviation = 0
                onset_deviation=0 
                onset_bangon+=1   
            onset_deviation_array.append(onset_deviation) 
            if (abs(duration_deviation)<duration_limit): # remove outliers
              duration_deviation_array.append(duration_deviation)
            else: 
              duration_violation+=1
        else:
            missing_onset_notes+=1
    print("lods,lodl,lodb, eods,eodl,eodb, bods,bodl,bodb,duration_violation")
    print(lods,lodl,lodb, eods,eodl,eodb, bods,bodl,bodb,duration_violation)
    return onset_deviation_array,duration_deviation_array,missing_onset_notes

# 3. Defining accuracy metrics.
import scipy

def match_events(gt_onsets, onsets, matching_window_size):
    """
    Finds best matching pairs so
       - distance between elements is no greater than matching_window_size
       - sum of all distances is is minimized
       - also returns the fidelity ( conformance to 100% hit notes)

    """
    # In case of performance issues for big piecs,
    # we could try to use simpler/faster local algorithm.
    m = scipy.spatial.distance_matrix([[x] for x in gt_onsets], [[x] for x in onsets])
    # don't consider events which are out of matching window size
    big_distance = 10 ** 6
    m[m > matching_window_size] = big_distance

    row_ind, col_ind = scipy.optimize.linear_sum_assignment(m)
    result = []
    missing_notes= 0
    deviated_notes = []
    for (x, y) in zip(row_ind, col_ind):
        if abs(gt_onsets[x] - onsets[y]) <= matching_window_size:
            result.append((x, y))
            # We are within marging lets get mlroe details on difference
            if (onsets[y]> gt_onsets[x]): # then it is late
              deviation = onsets[y] - gt_onsets[x]
            elif (onsets[y]< gt_onsets[x]): # then it is early
              diff =  gt_onsets[x] - onsets[y]
              deviation = -diff
            elif (onsets[y]== gt_onsets[x]): # then it is bang on
              deviation=0    
            deviated_notes.append(deviation)
        else:
            missing_notes+=1
     # How many missing as % of total?
    total_notes= len(onsets)
    delta_missing_notes= total_notes-missing_notes
    fidelity = round( 100.0*(delta_missing_notes/total_notes),4)     
    return result,fidelity,deviated_notes

def f_measure(precision, recall):
    if precision == 0 and recall == 0:
        return 0.0
    return 2.0 * precision*recall / (precision + recall)




def evaluate_accuracy(gt_onsets, onsets, matching_window_size):
    matching,_,_ = match_events(
        gt_onsets,
        onsets,
        matching_window_size)
    precision = float(len(matching)) / len(onsets)
    recall = float(len(matching)) / len(gt_onsets)
    f_measure_value = f_measure(precision, recall)
    return precision, recall, f_measure_value

#Setting the parameters try *2 also
windowSize = 1024*2º
hopSize = 512*2
startTimes = np.arange(0, raw_audio[0].size - windowSize, hopSize, dtype = int)#frame/window start indexes
numWindows = startTimes.size

"""The energy of a discrete time signal can be computed as:
\begin{equation}
energy = \sum_{n = 0}^{N-1} |x[n]|^2
\end{equation}
where x[n] refers to the discrete time signal sample at index n
"""

# Onset detection using Spectral Onset Processor blending ideas from Ramon
# myOnsetEnergyChecker
# Returns 
def myOnsetEnergyChecker(x,theFrameSize,theHopSize,thresh):
    NRG = [];
    #Main windowing and feature extraction loop
    #for frame in es.FrameGenerator(x, frameSize = windowSize, hopSize = hopSize, startFromZero = True):
    for frame in FrameGenerator(x, frameSize = theFrameSize, hopSize = theHopSize):
        NRG.append(es.Energy()(frame))
    NRG = np.array(NRG)
    NRG = NRG / np.max(NRG)
    #Applying energy threshold to decide wave split boundaries
    split_decision_func = np.zeros_like(NRG)
    split_decision_func[NRG > thresh] = 1 # was 0.005
    #Setting segment boundaries
    #Inserting a zero at the beginning since we will decide the transitions using a diff function
    split_decision_func = np.insert(split_decision_func, 0, 0)
    diff_split_decision = np.diff(split_decision_func)
    #Start indexes: transition from 0 to 1
    start_indexes = np.nonzero(diff_split_decision > 0)[0] * hopSize/fs
    #Stop indexes: transition from 1 to 0
    stop_indexes = np.nonzero(diff_split_decision < 0)[0] * hopSize/fs
    # TODO we have an issue here 
    #duration  = stop_indexes-start_indexes[1:len(start_indexes-1)]

    start_indexes=start_indexes[0:len(start_indexes)-1]
    return (start_indexes, stop_indexes)

frameSize = 2048
hopSize = 1024

from statistics import mean

myOnsetEnergyCheckerThreshold= 0.05 
matching_window_size = 0.05 # MIREX reference
p= []
r= []
f = []
OnsetCalculateOffsetOnset = []
onsetIndexArray =  []
offsetIndexArray =  []
durationIndexArray =  []
onset_deviationsArray  =  []
duration_deviationsArray  =  []
missing_onset_notesArray  =  []
for i in range(len(raw_audio)):
    onsetIndex, offsetIndex = myOnsetEnergyChecker(raw_audio[i],frameSize,hopSize,myOnsetEnergyCheckerThreshold) 
    onsetIndexArray.append(onsetIndex)
    offsetIndexArray.append(offsetIndex)
    
    # After break , calculate 
    precision, recal, f_measure_value=evaluate_accuracy(ground_t_onsets_array[i], onsetIndex, matching_window_size)
    print("WAV file number", i+1 ," precision, recall, f_measure_value",precision, recal, f_measure_value)
    print("\n")
    p.append(precision)
    r.append(recal)
    f.append(f_measure_value)

    p1=ground_t_onsets_array[i]
    p2=onsetIndex
    p3=ground_t_offsets_array[i] 
    p4=offsetIndex
    p5=matching_window_size
    onset_deviations,duration_deviations,missing_onset_notes =   match_duration(p1,p2,p3,p4,p5)
    print("WAV file number",i+1 ," missing_onset_notes",missing_onset_notes)

    onset_deviationsArray.append(onset_deviations)
    duration_deviationsArray.append(duration_deviations)
    missing_onset_notesArray.append(missing_onset_notes)


print("\n lo= late onset, eo = early onset, dl= duration long, ds = duration short, bo= bang on \n")

#################
plt.plot(np.arange(raw_audio[1].size)/float(fs), raw_audio[1],'b')
plt.axis([0,raw_audio[1].size/float(fs),min(raw_audio[1]),max(raw_audio[1])])
for i in onsetIndexArray[1]:
    plt.axvline(x=i, color='red')
plt.title("onsetIndexArray")
plt.show()
########################################################################################

plt.plot(np.arange(raw_audio[1].size)/float(fs), raw_audio[1],'b')
plt.axis([0,raw_audio[1].size/float(fs),min(raw_audio[1]),max(raw_audio[1])])
for i in ground_t_onsets_array[1]:
    plt.axvline(x=i, color='green')
plt.title("Ground Truth")
plt.show()

# offsetColmArray.append(onsetFirst)   
# offsetIndexArray.append(offsetIndex) 
plt.plot(np.arange(raw_audio[1].size)/float(fs), raw_audio[1],'b')
plt.axis([0,raw_audio[1].size/float(fs),min(raw_audio[1]),max(raw_audio[1])])
for i in offsetIndexArray[1]:
    plt.axvline(x=i, color='yellow')
plt.title("NRG (INDEX) based offset Algorithm to estimate")
plt.show()
########################################################################################


golden_onsets_0 = array(ground_t_offsets_array[1])

plt.plot(np.arange(raw_audio[1].size)/float(fs), raw_audio[1],'b')
plt.axis([0,raw_audio[1].size/float(fs),min(raw_audio[1]),max(raw_audio[1])])
for i in ground_t_offsets_array[1]:
    plt.axvline(x=i, color='green')
plt.title("Ground Truth Offset ANNOTATED")
plt.show()
########################################################################################

import pandas as pd
print(len(duration_deviationsArray))

index=0
while index <17:
  strname= 'Colm Durations'+str(index+1)
  data_timing_duration= { strname :duration_deviationsArray[index]}
  df = pd.DataFrame(data_timing_duration,columns=[strname])
  fig = px.histogram(df, x=strname)
  fig.show()
  index+=1

index=0
while index <17:
  strname= 'Colm Onsets '+str(index+1)
  data_timing_onsets= { strname :onset_deviationsArray[index]}
  df = pd.DataFrame(data_timing_onsets,columns=[strname])
  fig = px.histogram(df, x=strname)
  fig.show()
  index+=1

index=0
while index <9:
  fname= "drive/MyDrive/Bass/"+"00"+str(index+1)+"onset_dev.csv"
  print(fname)
  f = open(fname, 'r+')
  content_array = []
  for line in f:
    content_array.append(line)
  strname= 'Abesser onsets '+str(index+1)
  data_timing_onset= { strname :content_array}
  df = pd.DataFrame(data_timing_onset,columns=[strname])
  fig = px.histogram(df, x=strname)
  fig.show()
  f.close()
  index+=1
while index < 16:
  fname= "drive/MyDrive/Bass/"+"0"+str(index+1)+"onset_dev.csv"
  print(fname)
  f = open(fname, 'r+')
  content_array = []
  for line in f:
    content_array.append(line)
  strname= 'Abesser onsets '+str(index+1)
  data_timing_onset= { strname :content_array}
  df = pd.DataFrame(data_timing_onset,columns=[strname])
  fig = px.histogram(df, x=strname)
  fig.show()
  f.close()
  index+=1

#********************************************************************************************************
#
#
#
#          IMPORT THE RESULTS OF ABESSERS BASS-UNET method for 16 of he 17 IDMT DATASET WAV files.
#
#
#********************************************************************************************************



index=0
while index <9:
  fname= "drive/MyDrive/Bass/"+"00"+str(index+1)+"duration_dev.csv"
  print(fname)
  f = open(fname, 'r+')
  content_array = []
  for line in f:
    content_array.append(line)
  strname= 'Abesser onsets '+str(index+1)
  data_timing_onset= { strname :content_array}
  df = pd.DataFrame(data_timing_onset,columns=[strname])
  fig = px.histogram(df, x=strname)
  fig.show()
  f.close()
  index+=1
while index < 16:
  fname= "drive/MyDrive/Bass/"+"0"+str(index+1)+"duration_dev.csv"
  print(fname)
  f = open(fname, 'r+')
  content_array = []
  for line in f:
    content_array.append(line)
  strname= 'Abesser duration '+str(index+1)
  data_timing_duration= { strname :content_array}
  df = pd.DataFrame(data_timing_duration,columns=[strname])
  fig = px.histogram(df, x=strname)
  fig.show()
  f.close()
  index+=1